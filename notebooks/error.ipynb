{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1abb8cda-a8b3-4664-9f4c-63411d5d7469",
   "metadata": {},
   "source": [
    "   - 학습 데이터 (user_id : 10000 ~ 24999, 15000명)\n",
    "\n",
    "\n",
    "\t\t\t- train_err_data.csv : 시스템에 발생한 에러 로그\n",
    "\n",
    "\t\t\t- train_quality_data.csv : 시스템 퀄리티 로그\n",
    "\n",
    "\t\t\t- train_problem_data.csv : 사용자 불만 및 불만이 접수된 시간\n",
    "\n",
    "\n",
    "   - 테스트 데이터(user_id : 30000 ~ 44998, 14999명)\n",
    "\n",
    "\n",
    "\t\t\t- test_err_data.csv : 시스템에 발생한 에러 로그\n",
    "\n",
    "\t\t\t- test_quality_data.csv : 시스템 퀄리티 로그\n",
    "\n",
    "\t\t\t- sample_submission.csv : 사용자 불만 확률(0~1) (제출용)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bcae7e-9280-4035-a676-121321a8b662",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 사용할 Module & Data 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "73c297c9-42c2-4173-84d4-892afef240b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score ,f1_score, roc_auc_score, precision_recall_curve , auc\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import plot_importance ## Feature Importance 를 불러오기 위함이다\n",
    "import missingno as msno\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead4ae8c-e088-4a43-968f-4424a71ab4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/'\n",
    "train_err =pd.read_csv(PATH+'train_err.csv')\n",
    "train_problem =pd.read_csv(PATH+'train_problem.csv')\n",
    "train_quality =pd.read_csv(PATH+'train_quality.csv')\n",
    "test_err = pd.read_csv(PATH+'test_err.csv')\n",
    "test_quality = pd.read_csv(PATH+'test_quality.csv')\n",
    "\n",
    "\n",
    "# err data 는 user_id 15000 명의 대한것이다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2988eab7-2a77-4db3-be89-dc9793e11b65",
   "metadata": {
    "tags": []
   },
   "source": [
    "### time datetime으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22652e26-7e19-411e-a342-f522e72a1da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time 을 datetime 타입으로 바꾸고 바뀐지 확인\n",
    "# train_err.info()\n",
    "# test_err.info()\n",
    "# test_quality.info()\n",
    "# train_quality.info()\n",
    "# train_problem.info()\n",
    "# train_problem.time = train_problem.time.map(make_datetime)\n",
    "# train_quality.time = train_quality.time.map(make_datetime)\n",
    "# test_quality.time = test_quality.time.map(make_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07386882-d492-4aa2-a952-b102f60821ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바꾼 csv 저장\n",
    "\n",
    "# train_quality.to_csv('../data/train_quality.csv')\n",
    "# train_problem.to_csv('../data/train_problem.csv')\n",
    "# test_quality.to_csv('../data/test_quality.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b08bc09-8970-4c4a-ac8b-b62f8147a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time 을 datetime 타입으로 바꾸고 바뀐지 확인\n",
    "train_quality.time = pd.to_datetime(train_quality.time)\n",
    "test_err.time = pd.to_datetime(test_err.time)\n",
    "train_problem.time = pd.to_datetime( train_problem.time)\n",
    "train_err.time = pd.to_datetime(train_err.time)\n",
    "test_quality.time = pd.to_datetime(test_quality.time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55cd4682-267f-47fd-99f0-c8d87cec7529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_datetime(train_err_df.time)\n",
    "# pd.set_option('display.max_rows)\n",
    "# pandas display 할때 보여주는 최대 로우수와 컬럼수 지정  \n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_columns = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f803652-c83e-4d69-8c31-7ca4b0c1761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datetime(x):\n",
    "    x = str(x)\n",
    "    year = int(x[:4])\n",
    "    month = int(x[4:6])\n",
    "    day = int(x[6:8])\n",
    "    hour = int(x[8:10])\n",
    "    mim = int(x[10:12])\n",
    "    sec = int(x[12:])\n",
    "    return dt.datetime(year,month,day,hour,mim,sec)\n",
    "# make_datetime(20201101025616)\n",
    "# train_err_df['time']= train_err_df.time.map(make_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814b8696-16ee-47c1-8da9-13e2f431655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.MINYEAR\n",
    "dt.MAXYEAR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e559463-5f78-4fca-870e-8dbea0485c05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d54052-4cab-4143-91d7-efcbc1a93c25",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "- 불만접수를 err 데이터의 있는 모든 유저 가 불만접수를 했는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28cf480-62a2-4ecb-892b-ee5596ccc6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err_df.user_id.value_counts()\n",
    "train_problem_df.user_id.value_counts()\n",
    "train_quality_df.user_id.value_counts()\n",
    "#quality user_id 8281\n",
    "#problem user_id 5000\n",
    "#err user_id     15000\n",
    "#에러가 발생한 모든 유저가 불만 접수를 한것이 아님\n",
    "# 그러면 특정 유저"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe97898e-e195-4df1-8829-34af3191751d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 0609 한것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f54c7ac-98e4-4159-a065-4e727f26b792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583ff7b0-8d26-42fa-8bfa-2660ec8d83de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_quality_df.info() \n",
    "train_problem_df.info()\n",
    "train_err_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3fef2a-117c-4dab-b62a-25d3f4a12022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "null_columns = train_quality_df.columns[train_quality_df.isnull().sum() > 0].to_list()\n",
    "# 이거 왜 되지 ;; 여러개 의 행의 빈값 있는 것만 찾으려했는데 조건식 만들기가 힘드네 \n",
    "for column in null_columns:\n",
    "    display(train_quality_df[train_quality_df[column].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7511df59-6519-4715-82e6-f82bf0187727",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err_df.set_index(['user_id','errtype','model_nm']).loc[10000,'errcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0264fc62-d0d2-4d0c-af33-5a8a814783cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(train_err_df.errtype.unique())\n",
    "# 29제외 1부터 42까지 41가지 존재한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe0d9ed-6271-4985-94e5-1bfda7338c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_error = train_err_df[['user_id','errtype']].values\n",
    "id_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac81a794-e1c9-472d-9c14-1ebe11f29c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_err_df.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe4ee23-5400-4192-a950-78488719d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(train_err_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf891dc7-5d06-4eff-a0ff-6a9a261fd272",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_quality_df[train_quality_df.user_id == 10693]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad4043-7951-40f6-82d1-21087f06d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err_df[train_err_df.user_id == 10693]\n",
    "# user_id 10693 은 model_6 만 사용했는지는 모르지만 error 이것만떳어 fwver 이 10 이라고 error 데이터에서는 보이는 그러면\n",
    "# error 가 발생하고 quality 를 2시간동안 10분마다 수집하니까  근데 보면 20일에 발생한 에러는 없어 에러를 거의 2 분 3분마다 발생시키는데 \n",
    "# 무슨 에러인지 모르겠네 어차피 이건 model_6 fwver 10에 대한 에러들이야"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b988d1cd-6a4e-43c2-be6a-45854163121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# quailty 에서 fwver 가 nan인게 뭐뭐가 있는지 fwver 가 빈것들은 다 퀄리티 0 과 2가 비어있는지 봐보자\n",
    "train_quality_df.loc[train_quality_df.fwver.isnull(),['quality_0','quality_2']].notnull().sum()\n",
    "# 다 비어 있다 그러면 모델이 같은지 한번 봐보자\n",
    "null_qual_0_1 = train_quality_df.loc[train_quality_df.fwver.isnull(),'user_id'].unique() # 개수는 59개\n",
    "\n",
    "def isin_null_0_1(x):\n",
    "    if x in null_qual_0_1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "null_0_1 = train_err_df[train_err_df.user_id.map(isin_null_0_1)]\n",
    "'''\n",
    "model_6    1639\n",
    "model_0    1630\n",
    "model_2     783\n",
    "model_3      43\n",
    "'''\n",
    "null_0_1[null_0_1.model_nm == \"model_6\"].fwver.value_counts()\n",
    "#array(['model_6', 'model_3', 'model_0', 'model_2'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ecee83-2fe2-4b2b-9144-c40c07739138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 종류가 몇가지나 있나 한번 봐보자 \n",
    "train_err_df.model_nm.value_counts()\n",
    "# 빈것들의 에러코드는 같은지 or model 이 같은지 \n",
    "# 퀄리티 별 숫자가 같은지 로봐보자 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c30af-9ea7-4719-a7a1-1efba142a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_quality_df[train_quality_df.columns[3:]].iloc[:,0].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200468a3-3122-47af-ad7b-69b5b5b3cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null_0_1.errtype.value_counts()\n",
    "# model_nm 과 error 타입을 연결시키는건 좀 힘들고\n",
    "# user_id 별로 무슨 error type 이나 error code에 대한 불만을 많이 썻는지\n",
    "# 그 에러들의 퀄리티 점수 분포는 어떻게 되는지 로 보면 될거같은데\n",
    "# 결측 치 채우기는 다음에 위에꺼 부터\n",
    "plt.figure(figsize =(10,5))\n",
    "train_problem_df.user_id.value_counts().hist()\n",
    "# plt.ylim(0,100)\n",
    "plt.show()\n",
    "# 대부분 의 고객이 불만은 한번 표시 했다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d2814a-10c9-4eab-9171-8c5fa6de1412",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 0610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b9024-2142-4246-b0ad-d9bdaff865f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err.info()\n",
    "train_problem_df.info()\n",
    "train_quality_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "60407342-69c1-4f39-b6cf-f57792005a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>model_nm</th>\n",
       "      <th>fwver</th>\n",
       "      <th>errtype</th>\n",
       "      <th>errcode</th>\n",
       "      <th>quality_0</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_3</th>\n",
       "      <th>quality_4</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_6</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_9</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "      <th>quality_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10050</td>\n",
       "      <td>2020-11-04 16:30:00</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10050</td>\n",
       "      <td>2020-11-04 16:30:00</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10050</td>\n",
       "      <td>2020-11-04 16:30:00</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10050</td>\n",
       "      <td>2020-11-04 16:30:00</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10050</td>\n",
       "      <td>2020-11-04 16:30:00</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>24934</td>\n",
       "      <td>2020-11-24 11:20:00</td>\n",
       "      <td>model_4</td>\n",
       "      <td>03.11.1167</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2,396</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>24934</td>\n",
       "      <td>2020-11-24 11:20:00</td>\n",
       "      <td>model_4</td>\n",
       "      <td>03.11.1167</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2,396</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>24934</td>\n",
       "      <td>2020-11-24 11:20:00</td>\n",
       "      <td>model_4</td>\n",
       "      <td>03.11.1167</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2,396</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>24934</td>\n",
       "      <td>2020-11-24 11:20:00</td>\n",
       "      <td>model_4</td>\n",
       "      <td>03.11.1167</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2,396</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>24934</td>\n",
       "      <td>2020-11-24 11:20:00</td>\n",
       "      <td>model_4</td>\n",
       "      <td>03.11.1167</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2,396</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1356 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                time model_nm       fwver  errtype errcode  \\\n",
       "0       10050 2020-11-04 16:30:00  model_1  04.16.3553       32      80   \n",
       "1       10050 2020-11-04 16:30:00  model_1  04.16.3553       32      80   \n",
       "2       10050 2020-11-04 16:30:00  model_1  04.16.3553       32      80   \n",
       "3       10050 2020-11-04 16:30:00  model_1  04.16.3553       32      80   \n",
       "4       10050 2020-11-04 16:30:00  model_1  04.16.3553       32      80   \n",
       "...       ...                 ...      ...         ...      ...     ...   \n",
       "1351    24934 2020-11-24 11:20:00  model_4  03.11.1167       27       1   \n",
       "1352    24934 2020-11-24 11:20:00  model_4  03.11.1167       27       1   \n",
       "1353    24934 2020-11-24 11:20:00  model_4  03.11.1167       27       1   \n",
       "1354    24934 2020-11-24 11:20:00  model_4  03.11.1167       27       1   \n",
       "1355    24934 2020-11-24 11:20:00  model_4  03.11.1167       27       1   \n",
       "\n",
       "      quality_0  quality_1  quality_2  quality_3  quality_4 quality_5  \\\n",
       "0           0.0          0        0.0          0          0         0   \n",
       "1           0.0          0        0.0          0          0         0   \n",
       "2           0.0          0        0.0          0          0         0   \n",
       "3           0.0          0        0.0          0          0         1   \n",
       "4           0.0          0        0.0          0          0         0   \n",
       "...         ...        ...        ...        ...        ...       ...   \n",
       "1351        NaN          0        0.0          0          0       185   \n",
       "1352        NaN          0        0.0          0          0       136   \n",
       "1353        NaN          0        0.0          0          0       156   \n",
       "1354        NaN          0        0.0          0          0       148   \n",
       "1355        NaN          0        0.0          0          0       159   \n",
       "\n",
       "      quality_6 quality_7 quality_8 quality_9 quality_10  quality_11  \\\n",
       "0             0         0         0         0          7           0   \n",
       "1             0         0         0         0          7           0   \n",
       "2             0         0         0         0          7           0   \n",
       "3             0         0         0         0          7           0   \n",
       "4             0         0         0         0          7           0   \n",
       "...         ...       ...       ...       ...        ...         ...   \n",
       "1351          0         0         0         0      2,396           0   \n",
       "1352          0         0         0         0      2,396           0   \n",
       "1353          0         0         0         0      2,396           0   \n",
       "1354          0         0         0         0      2,396           0   \n",
       "1355          0         0         0         0      2,396           0   \n",
       "\n",
       "      quality_12  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "1351           0  \n",
       "1352           0  \n",
       "1353           0  \n",
       "1354           0  \n",
       "1355           0  \n",
       "\n",
       "[1356 rows x 19 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#중복값 확인해서 똑같은걸 처리해준다\n",
    "#왜냐 왜냐 음 왜일까 수학적으로 가중치를 더주게 될거라는 느낌은 무엇을 보고 느낀걸까 아마 그럴거라고 듣기만해서 일텐데 \n",
    "#오차를 구하는 방식에서 똑같은 것만 있다면 우린 loss를 줄이는 방식인가 ? lgbm 이 어떤식으로 작동했던건지 기억이 안나서 잘안돼네\n",
    "\n",
    "# train_err_df # 16553663row\n",
    "# train_err= train_err_df.drop_duplicates(keep= 'last', ignore_index = True)\n",
    "# train_problem_df.duplicated().sum()# 중복값 불만접수 데이터에는 없고\n",
    "\n",
    "# 어 그러면 2시간 동안 한번씩 찍힌다고 했는데 한번만 찍힌것도 있나\n",
    "# train_quality_df[train_quality_df.time.duplicated(keep=False)]\n",
    "# 확인 결과 없고 당연하네\n",
    "\n",
    "# dup_user = train_quality_df.loc[:,'user_id'].unique()\n",
    "# dup_user # 처음 중복되는 값을 여기도 확인하려했었는데 반복된다고했고 time 을 에러가 뜬순간으로 처리해놔서 구별이 되게했구나 아아아아아 분 초를 없앴어\n",
    "# 분초를 진짜 없앴는지 봐보자\n",
    "#train_err # 일단 에러는 시분초 다 세세히 적혀있어\n",
    "\n",
    "# train_quality_df.time.map(lambda x: x.minute).value_counts()\n",
    "# quality는\n",
    "'''\n",
    "20    151224\n",
    "0     145920\n",
    "10    140652\n",
    "30    133896\n",
    "50    131316\n",
    "40    125616\n",
    "'''\n",
    "# merge on=None 이면 두 데이터셋의 공통 열이름 을 기준으로 inner 조인 하게된다\n",
    "# 여기서는 'time', 'user_id', 'fwver' 컬럼을 기준으로 조인하게된것이다\n",
    "pd.merge(train_err, train_quality)\n",
    "\n",
    "# train_quality_df.time.map(lambda x: x.second).value_counts()\n",
    "#0    828624 초는 다없애고 분은 10분 단위에 맞춰서 한거같다 하나하나 비교해야되는데 능력부족\n",
    "\n",
    "# train_quality_df[train_quality_df['user_id'] ==dup_user[2]]\n",
    "# 이건 에러가 뜨고 quality_0~12 가 점수가 같은지 같은에러에는 같은지 봐볼라고했다 \n",
    "# 에러가 같은건 같은 시간대에 같은 user_id fwver 으로 같은 에러라고 판단했고\n",
    "# 거의 같은 양상을 보이지만 완전히 같지 않기에 항상 quality가 똑같다고 볼수없다 에러가 안떳는데도 퀄리티가 찍히는 데이터는 아닌거같은데 확인은 해봐야겠고\n",
    "\n",
    "# quality data 를 왜안썻는지 이유될만한거랑\n",
    "# 학습 데이터를 어떻게 만들었는지\n",
    "# 레이블 설정을 어떻게 만들었는지 따로 이게 target 이다 나라고 우리가 느끼기엔 처음에 없었다.\n",
    "# py캐럿 찾아 볼거\n",
    "# xgboost 성능 평가 표 \n",
    "\n",
    "\n",
    "\n",
    "# 품질 이 양수와 음수를 보고 품질이 음수일때 불만 접수를 하는지 \n",
    "# 아 근데 에러가 떳을때 quality log 를 찍는단 말이야 그러면 그래도 의미 있을거같애\n",
    "# 모델이 뭔지를 안다면 안찍히는것은 기능 유추를 해볼수 있을텐데 그것도 모르겠고\n",
    "# LG 는 가전제품 생산하는 회사야 그러면 log 를 찍을수있는건가 ? 당연한건가 품질로그를?\n",
    "\n",
    "# 불만을 표한 error 가 무엇일까 그걸 찾고 그 순간에 퀄리티 점수 는 ? ㅇㅋ 이걸로 간다 \n",
    "# merge_df = pd.merge(train_problem_df,train_err , on = 'user_id')\n",
    "# merge_df[merge_df['user_id'] == 19224][:100]\n",
    "# 19224 \t2020-11-02 20:00:00\n",
    "\n",
    "# outlier 여부 확인도 해야겠네\n",
    "# quality 유저별 펌웨어별 그리고 시간별 평균 합  분산 ? ㅇ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f0af6653-2f9b-4fc7-bf83-ee902a99320f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_nm :\n",
      "['model_3' 'model_2' 'model_0' 'model_1' 'model_7' 'model_4' 'model_5'\n",
      " 'model_8' 'model_6']\n",
      "fwver :\n",
      " ['05.15.2138' '04.33.1185' '04.33.1261' '04.22.1750' '04.22.1778'\n",
      " '04.16.3553' '04.33.1149' '04.16.3571' '05.66.3237' '05.66.3571'\n",
      " '03.11.1149' '04.22.1684' '03.11.1167' '04.82.1684' '04.82.1778'\n",
      " '04.33.1171' '04.73.2237' '10' '04.82.1730' '04.73.2571' '8.5.3'\n",
      " '04.22.1666' '03.11.1141' '05.15.2120' '04.33.1125' '04.16.3439'\n",
      " '04.22.1442' '04.33.1095' '04.16.3569' '05.15.2090' '05.15.3104'\n",
      " '05.15.2122' '04.22.1656' '04.16.2641' '05.15.2114' '04.16.3345'\n",
      " '05.15.2092']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>model_nm</th>\n",
       "      <th>fwver</th>\n",
       "      <th>errtype</th>\n",
       "      <th>errcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9322999</th>\n",
       "      <td>19224</td>\n",
       "      <td>2020-11-01 02:31:45</td>\n",
       "      <td>model_0</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9323000</th>\n",
       "      <td>19224</td>\n",
       "      <td>2020-11-01 02:32:07</td>\n",
       "      <td>model_0</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9323001</th>\n",
       "      <td>19224</td>\n",
       "      <td>2020-11-01 02:32:07</td>\n",
       "      <td>model_0</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9323002</th>\n",
       "      <td>19224</td>\n",
       "      <td>2020-11-01 02:32:11</td>\n",
       "      <td>model_0</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9323003</th>\n",
       "      <td>19224</td>\n",
       "      <td>2020-11-01 02:32:26</td>\n",
       "      <td>model_0</td>\n",
       "      <td>04.22.1750</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9323884</th>\n",
       "      <td>19224</td>\n",
       "      <td>2020-11-30 20:52:57</td>\n",
       "      <td>model_0</td>\n",
       "      <td>04.22.1778</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9323885</th>\n",
       "      <td>19224</td>\n",
       "      <td>2020-11-30 20:52:57</td>\n",
       "      <td>model_0</td>\n",
       "      <td>04.22.1778</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9323886</th>\n",
       "      <td>19224</td>\n",
       "      <td>2020-11-30 20:53:03</td>\n",
       "      <td>model_0</td>\n",
       "      <td>04.22.1778</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9323887</th>\n",
       "      <td>19224</td>\n",
       "      <td>2020-11-30 20:53:19</td>\n",
       "      <td>model_0</td>\n",
       "      <td>04.22.1778</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9323888</th>\n",
       "      <td>19224</td>\n",
       "      <td>2020-11-30 23:03:18</td>\n",
       "      <td>model_0</td>\n",
       "      <td>04.22.1778</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>890 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id                time model_nm       fwver  errtype errcode\n",
       "9322999    19224 2020-11-01 02:31:45  model_0  04.22.1750       15       1\n",
       "9323000    19224 2020-11-01 02:32:07  model_0  04.22.1750       33       2\n",
       "9323001    19224 2020-11-01 02:32:07  model_0  04.22.1750       15       1\n",
       "9323002    19224 2020-11-01 02:32:11  model_0  04.22.1750       15       1\n",
       "9323003    19224 2020-11-01 02:32:26  model_0  04.22.1750       12       1\n",
       "...          ...                 ...      ...         ...      ...     ...\n",
       "9323884    19224 2020-11-30 20:52:57  model_0  04.22.1778       31       1\n",
       "9323885    19224 2020-11-30 20:52:57  model_0  04.22.1778       15       1\n",
       "9323886    19224 2020-11-30 20:53:03  model_0  04.22.1778       16       1\n",
       "9323887    19224 2020-11-30 20:53:19  model_0  04.22.1778       31       0\n",
       "9323888    19224 2020-11-30 23:03:18  model_0  04.22.1778       15       1\n",
       "\n",
       "[890 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19224</td>\n",
       "      <td>2020-11-02 20:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                time\n",
       "0    19224 2020-11-02 20:00:00"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# err dataset 에서 중복 되는값들도 있어서 삭제했고\n",
    "# 차라리 너무 많은 feature 가 되버리는 errcode를 사용해서 학습한 모델이랑 errtype 만 쓴 모델을 둘다 만들어봐서 예측 성능 비교를 해보고 안해볼걸그랬네\n",
    "# 안해본게 좀 흠이다\n",
    "\n",
    "print(f'model_nm :\\n{train_err.model_nm.unique()}')\n",
    "print(f'fwver :\\n {train_err.fwver.unique()}')\n",
    "# pd.merge(train_err , train_problem, on=['user_id','time'])\n",
    "train_problem = train_problem.drop(columns=['Unnamed: 0'])\n",
    "display(train_err[train_err.user_id == train_problem.user_id.unique()[0]])\n",
    "train_problem[train_problem.user_id == train_problem.user_id.unique()[0]]\n",
    "# train_quality = train_quality.drop(columns=['Unnamed: 0'])\n",
    "# print(f'train_err 의 user_id 수 : {len(train_err.user_id.unique())}')\n",
    "# print(f'train_quality 에서 user_id 수 : {len(train_quality.user_id.unique())}')\n",
    "# print(f'train_problem 에 user_id 수 : {len(train_problem.user_id.unique())}')\n",
    "# # len(train_err.errcode.unique())\n",
    "# print('quality 와 problem 둘다에 존재하는 user_id 수 : {}'.format(len(pd.merge(train_quality , train_problem, on= 'user_id').user_id.unique())))\n",
    "# # f'quality 와 problem 같은 user_id 수 :{len(pd.merge(train_quality , train_problem, on= 'user_id').user_id.unique())}'\n",
    "# print('quality 에 없고 problem 에만 존재하는 user_id 수 : {}'.format(len(train_problem.user_id.unique()) - len(pd.merge(train_quality , train_problem, on= 'user_id').user_id.unique())))\n",
    "# print(f'quality 와 problem 같은 user_id 수 :{len(train_problem.user_id.unique()) - len(pd.merge(train_quality , train_problem, on= 'user_id').user_id.unique())}')\n",
    "# train_quality.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9b850016-3f39-4a21-b4dd-457008bf8f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1                     8097696\n",
      "0                     2594264\n",
      "connection timeout    1835262\n",
      "B-A8002                575827\n",
      "80                     333929\n",
      "                       ...   \n",
      "4329                        1\n",
      "3765                        1\n",
      "4105                        1\n",
      "5779                        1\n",
      "25999                       1\n",
      "Name: errcode, Length: 2805, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>model_nm</th>\n",
       "      <th>fwver</th>\n",
       "      <th>errtype</th>\n",
       "      <th>errcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>2020-11-01 02:56:16</td>\n",
       "      <td>model_3</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>2020-11-01 03:03:09</td>\n",
       "      <td>model_3</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>2020-11-01 03:03:09</td>\n",
       "      <td>model_3</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>2020-11-01 05:05:14</td>\n",
       "      <td>model_3</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10000</td>\n",
       "      <td>2020-11-01 05:05:16</td>\n",
       "      <td>model_3</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15367993</th>\n",
       "      <td>24999</td>\n",
       "      <td>2020-11-30 14:21:05</td>\n",
       "      <td>model_3</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15367994</th>\n",
       "      <td>24999</td>\n",
       "      <td>2020-11-30 16:15:10</td>\n",
       "      <td>model_3</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15367997</th>\n",
       "      <td>24999</td>\n",
       "      <td>2020-11-30 16:30:51</td>\n",
       "      <td>model_3</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15367998</th>\n",
       "      <td>24999</td>\n",
       "      <td>2020-11-30 17:26:25</td>\n",
       "      <td>model_3</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15368001</th>\n",
       "      <td>24999</td>\n",
       "      <td>2020-11-30 21:06:25</td>\n",
       "      <td>model_3</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8097696 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id                time model_nm       fwver  errtype errcode\n",
       "0           10000 2020-11-01 02:56:16  model_3  05.15.2138       15       1\n",
       "1           10000 2020-11-01 03:03:09  model_3  05.15.2138       12       1\n",
       "2           10000 2020-11-01 03:03:09  model_3  05.15.2138       11       1\n",
       "3           10000 2020-11-01 05:05:14  model_3  05.15.2138       16       1\n",
       "5           10000 2020-11-01 05:05:16  model_3  05.15.2138       26       1\n",
       "...           ...                 ...      ...         ...      ...     ...\n",
       "15367993    24999 2020-11-30 14:21:05  model_3  05.15.2138       15       1\n",
       "15367994    24999 2020-11-30 16:15:10  model_3  05.15.2138       16       1\n",
       "15367997    24999 2020-11-30 16:30:51  model_3  05.15.2138       15       1\n",
       "15367998    24999 2020-11-30 17:26:25  model_3  05.15.2138       16       1\n",
       "15368001    24999 2020-11-30 21:06:25  model_3  05.15.2138       15       1\n",
       "\n",
       "[8097696 rows x 6 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print('train_err 데이터 개수 :{}'.format(format( len(train_err),',')))\n",
    "# print('train_quality 데이터 개수: {}'.format(format(len(train_quality),',')))\n",
    "# print(format(len(train_quality),','))\n",
    "\n",
    "# num = 12300000.111\n",
    "\n",
    "# print(format(num, ','))\n",
    "print(train_err.errcode.value_counts())\n",
    "train_err[train_err.errcode == '1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e0fba57c-d766-40c9-ba7e-41f2ce11dafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_errtype = np.sort(train_err.errtype.unique())\n",
    "train_errtype\n",
    "test_errtype = np.sort(test_err.errtype.unique())\n",
    "test_errtype == train_errtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b45ed21-f4d6-4293-b0e6-9205d9e5dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_id_max= 14999\n",
    "train_user_id_min= 10000\n",
    "train_user_id_num= 15000\n",
    "\n",
    "labels = np.zeros(train_user_id_num)\n",
    "# print(labels.dtype)\n",
    "labels[train_problem_df.user_id.unique()-10000] = 1\n",
    "labels = labels.astype('int16')\n",
    "\n",
    "def labeling(x):\n",
    "    return labels[x -10000]\n",
    "\n",
    "train_err['problem'] = train_err.user_id.map(labeling)\n",
    "train_err\n",
    "train_quality_df['problem']= train_quality_df.user_id.map(labeling)\n",
    "train_quality_df\n",
    "# 각 user_id 보고 거기다 라벨 붙이기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee23854-88a3-4242-8680-1c7b66124a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re_number = re.compile(\"\\d\")\n",
    "# re_number.search('6a')\n",
    "# 확실히 에러 가 뜬다고 다 적은게 아니다 결측값이 있다 \n",
    "# 없어 불리 할수밖에없다 \n",
    "# 합쳐져 사용하고싶다 빈게 많을것이다 맞냐 틀리냐 \n",
    "# 빈것을 어떻게 합쳐서 쓰냐 하면\n",
    "# train Err 랑 problem 만쓴거 보다 성능이 안좋다 그러면 \n",
    "# 여러개 시간별로 다양한 데이터가 있다 그러면 어떻게 사용할것이냐 ?\n",
    "# 이데이터에 대해서 얼마나 이해하고있는지 고민해보고 \n",
    "# 왜 이문제를 선택했는지 \n",
    "# 시간 차이 테스트 랑 트레인 \n",
    "# 시간차이를 봐봐야돼 퀄리티랑 에러도 보고 그렇게 다봐봐야돼\n",
    "# 원하는 데이터 타입의 컬럼만 뽑기\n",
    "# train_quality_df.select_dtypes('object')\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize = (21,7))\n",
    "\n",
    "sns.heatmap(train_err.corr(), ax= axs[0], annot = True)\n",
    "sns.heatmap(train_problem_df.corr(), ax= axs[1], annot = True)\n",
    "sns.heatmap(train_quality_df.corr(), ax= axs[2], annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5535c1d-c94f-4ff6-8944-027cadb5df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_quality_df.corr().iloc[:,2:]\n",
    "# 영향을 끼친다를 어떻게 판단하는지 영향이 있다 느껴지면 그걸 어떻게 활용하는지 모르겠다\n",
    "train_quality_df.describe()\n",
    "train_quality_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0ed0d-a7f6-420c-ade9-d29af67b960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_quality_df['quality_5'].apply(lambda x :  0 if type(x) != str and math.isnan(x)   else int(x.replace(',','')) )\n",
    "# train_quality_df[train_quality_df.iloc[:,8].isna()]\n",
    "# type(train_quality_df.loc[58907].loc['quality_5'])\n",
    "train_quality_df.select_dtypes('object').iloc[:,2].apply(lambda x :  0 if (type(x) != str and math.isnan(x)) int(x.replace(',','')) elif type(x) == str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2f7aca-c059-48dd-8746-b4b5437dbd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f548ac-a407-428a-aee2-d2599ce317b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# b = math.nan\n",
    "# print(np.isnan(b))\n",
    "\n",
    "# a = np.nan\n",
    "# print(np.isnan(a))\n",
    "\n",
    "# (lambda x : 0.0 if math.isnan(x) else x)(train_quality_df.loc[58907].loc['quality_5'])\n",
    "# train_quality_df.loc[58907].loc['quality_5']\n",
    "type('str') == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcba693-bb6a-4f35-9e16-2bca4fb6a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "b = math.nan\n",
    "print(math.isnan(b))\n",
    "\n",
    "a = np.nan\n",
    "print(math.isnan(0.1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374fd9aa-00b4-4801-9523-350c6fc34c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0ecac75-a0e4-40d8-8946-faaacab3be93",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debbe5d1-91b3-49c4-9499-01055482c869",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 초기 Errtype만을 이용하여 데이터를 학습시키기는 것으로 시작\n",
    "- label 은 problem set 이 불만 접수를 한 유저 이다\n",
    "  시계열 데이터인 이 데이터에서 시간 에 대한 활용은 아직 못하였기때문에 시간은 사용하지않음\n",
    "  그러므로 problem 의 존재하는 user_id 불만접수 유저 label = 1로 지정 나머지는 0 \n",
    "\n",
    "- user_id 별로 errtype 별 발생 횟수만을 학습 데이터로 전처리하여 학습시킨다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5623141c-4348-4de3-afac-6d300caff240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_err_data 의 유저 아이디는 15000명이고 10000~24999이기 때문에\n",
    "# 더 연산이 빠르게 ndarray를 새로만들어서 0을 user_id 10000으로 해서 레이블을 붙인다\n",
    "def make_label(df):\n",
    "    problem = np.zeros(15000)\n",
    "    problem[df.user_id -10000] = 1\n",
    "    return problem\n",
    "# np.zeros(15000)\n",
    "# train_problem[train_problem.user_id==10001]\n",
    "\n",
    "problem = make_label(train_problem)\n",
    "train_y = problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3101c747-0ec7-4fc3-9735-f667762653d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 16532648/16532648 [00:14<00:00, 1112356.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14999, 42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(np.sort(train_err.errtype.unique())) # 이전 EDA에서도 봤지만 1~42 중 29가 빠진 41개의 errtype이 있다\n",
    "\n",
    "test_user_id_max = 44998\n",
    "test_user_id_min = 30000\n",
    "test_user_number = 14999\n",
    "train_user_id_max = 24999\n",
    "train_user_id_min = 10000\n",
    "train_user_number = 15000\n",
    "def data_pre(err, min_num , max_num , user_number):\n",
    "    # user_errtype = np.zeros((15000,41))\n",
    "    user_errtype2= np.zeros((user_number,42))\n",
    "    \n",
    "\n",
    "    for user_id , type_num in tqdm(err[['user_id','errtype']].values):  # colmuns 명들을 변수로 바꿔놓을까 했는데 여기서만 쓸거같네 이함수는\n",
    "        # if type_num > 28:\n",
    "        #     user_errtype[user_id-10000,type_num-2] += 1\n",
    "        # else:\n",
    "        # user_errtype[user_id-10000,type_num-1] += 1\n",
    "        user_errtype2[user_id-min_num,type_num-1] += 1\n",
    "    return user_errtype2\n",
    "\n",
    "# test_X = data_pre(test_err, test_user_id_min, test_user_id_max, test_user_number)\n",
    "# test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01beab17-e5be-400b-95c1-2fa49a6a76b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_X)\n",
    "test_df.to_csv(PATH + 'test_X.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ec2667e-faf5-4fef-96bd-6140ab478327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16532648 entries, 0 to 16532647\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Dtype         \n",
      "---  ------      -----         \n",
      " 0   Unnamed: 0  int64         \n",
      " 1   user_id     int64         \n",
      " 2   model_nm    object        \n",
      " 3   fwver       object        \n",
      " 4   errtype     int64         \n",
      " 5   errcode     object        \n",
      " 6   time        datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(3), object(3)\n",
      "memory usage: 882.9+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>model_nm</th>\n",
       "      <th>fwver</th>\n",
       "      <th>errtype</th>\n",
       "      <th>errcode</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30000</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-01 03:02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30000</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-11-01 03:02:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>30000</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-01 03:02:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30000</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-01 03:02:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>30000</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-01 03:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16532643</th>\n",
       "      <td>16532643</td>\n",
       "      <td>44998</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-30 21:00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16532644</th>\n",
       "      <td>16532644</td>\n",
       "      <td>44998</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-30 21:18:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16532645</th>\n",
       "      <td>16532645</td>\n",
       "      <td>44998</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-30 21:18:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16532646</th>\n",
       "      <td>16532646</td>\n",
       "      <td>44998</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-30 21:22:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16532647</th>\n",
       "      <td>16532647</td>\n",
       "      <td>44998</td>\n",
       "      <td>model_1</td>\n",
       "      <td>04.16.3553</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-30 21:23:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16532648 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0  user_id model_nm       fwver  errtype errcode  \\\n",
       "0                  0    30000  model_1  04.16.3553       31       1   \n",
       "1                  1    30000  model_1  04.16.3553       33       2   \n",
       "2                  2    30000  model_1  04.16.3553       15       1   \n",
       "3                  3    30000  model_1  04.16.3553       22       1   \n",
       "4                  4    30000  model_1  04.16.3553       11       1   \n",
       "...              ...      ...      ...         ...      ...     ...   \n",
       "16532643    16532643    44998  model_1  04.16.3553       40       0   \n",
       "16532644    16532644    44998  model_1  04.16.3553       31       1   \n",
       "16532645    16532645    44998  model_1  04.16.3553       15       1   \n",
       "16532646    16532646    44998  model_1  04.16.3553       16       1   \n",
       "16532647    16532647    44998  model_1  04.16.3553       31       0   \n",
       "\n",
       "                        time  \n",
       "0        2020-11-01 03:02:27  \n",
       "1        2020-11-01 03:02:27  \n",
       "2        2020-11-01 03:02:28  \n",
       "3        2020-11-01 03:02:56  \n",
       "4        2020-11-01 03:03:00  \n",
       "...                      ...  \n",
       "16532643 2020-11-30 21:00:50  \n",
       "16532644 2020-11-30 21:18:31  \n",
       "16532645 2020-11-30 21:18:32  \n",
       "16532646 2020-11-30 21:22:59  \n",
       "16532647 2020-11-30 21:23:16  \n",
       "\n",
       "[16532648 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(test_err.info())\n",
    "# test_err.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e8d18a7-89b9-4f23-b272-7862f4aaa6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2      3     4    5    6    7    8    9  ...    32    33  \\\n",
       "0      0.0  0.0  8.0  104.0   0.0  1.0  1.0  0.0  0.0  7.0  ...   0.0   0.0   \n",
       "1      0.0  0.0  0.0    0.0  48.0  1.0  1.0  0.0  0.0  0.0  ...  10.0  18.0   \n",
       "2      0.0  0.0  2.0  131.0   1.0  2.0  1.0  0.0  0.0  1.0  ...   0.0   0.0   \n",
       "3      0.0  0.0  0.0    0.0   2.0  1.0  1.0  0.0  0.0  0.0  ...   8.0   0.0   \n",
       "4      0.0  0.0  0.0    1.0   0.0  3.0  4.0  0.0  0.0  0.0  ...  16.0   0.0   \n",
       "...    ...  ...  ...    ...   ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "14995  0.0  0.0  0.0    0.0   2.0  5.0  5.0  0.0  0.0  0.0  ...   5.0   0.0   \n",
       "14996  0.0  0.0  0.0    0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "14997  0.0  0.0  0.0    1.0   8.0  1.0  1.0  0.0  0.0  0.0  ...  16.0  12.0   \n",
       "14998  0.0  0.0  0.0    0.0   0.0  0.0  0.0  0.0  0.0  0.0  ...  15.0   2.0   \n",
       "14999  0.0  0.0  4.0  188.0   7.0  5.0  4.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "        34   35   36   37   38     39    40   41  \n",
       "0      0.0  0.0  0.0  0.0  0.0    0.0   0.0  0.0  \n",
       "1      0.0  1.0  1.0  0.0  0.0  113.0  56.0  1.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0    0.0   0.0  0.0  \n",
       "3      0.0  1.0  1.0  2.0  0.0   17.0   1.0  0.0  \n",
       "4      0.0  1.0  1.0  0.0  0.0    4.0   0.0  2.0  \n",
       "...    ...  ...  ...  ...  ...    ...   ...  ...  \n",
       "14995  0.0  0.0  0.0  0.0  0.0    9.0   7.0  4.0  \n",
       "14996  0.0  0.0  0.0  0.0  0.0    0.0   0.0  0.0  \n",
       "14997  0.0  1.0  1.0  0.0  0.0   58.0   7.0  5.0  \n",
       "14998  0.0  1.0  1.0  0.0  0.0    6.0   0.0  0.0  \n",
       "14999  0.0  0.0  0.0  0.0  0.0    0.0   0.0  0.0  \n",
       "\n",
       "[15000 rows x 42 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0      0.0\n",
       "1      1.0\n",
       "2      0.0\n",
       "3      0.0\n",
       "4      1.0\n",
       "...    ...\n",
       "14995  0.0\n",
       "14996  0.0\n",
       "14997  1.0\n",
       "14998  1.0\n",
       "14999  0.0\n",
       "\n",
       "[15000 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_X = pd.DataFrame(data_pre(train_err,train_user_id_min,train_user_id_max,train_user_number))\n",
    "# train_data2 = pd.DataFrame(user_errtype)\n",
    "# train_label = pd.Series(train_y)\n",
    "\n",
    "# train_X.to_csv(PATH+'train_X.csv',index = False) # index 까지 저장하면 불러올때 unnamed 로 컬럼이 하나 더생겨버린다\n",
    "# train_data2.to_csv('../data/train_data2.csv', index= False)\n",
    "# train_label.to_csv('../data/label.csv', index= False)\n",
    "PATH = '../data/'\n",
    "train_X = pd.read_csv(PATH+'train_X.csv')\n",
    "train_y = pd.read_csv(PATH+'label.csv')\n",
    "test_X = pd.read_csv(PATH +'test_X.csv')\n",
    "display(train_X)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e9c5d3-0b08-4d91-b566-766ccbf8109b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modeling & Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73447bfb-a5ef-4995-b1ed-aa68b30061d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LightBGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9caa38cd-fd52-420a-936f-c1462c310b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels = y_true.get_label()\n",
    "    p ,r , _ = precision_recall_curve(labels, probas_pred)\n",
    "    score = auc(r,p)\n",
    "    return \"pr_auc\", score, True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "56bd4d3f-5e73-43f9-8546-3192dbf43854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3633, number of negative: 8367\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4300\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 41\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302750 -> initscore=-0.834237\n",
      "[LightGBM] [Info] Start training from score -0.834237\n",
      "[1]\tvalid_0's auc: 0.761669\tvalid_0's pr_auc: 0.75827\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[2]\tvalid_0's auc: 0.773808\tvalid_0's pr_auc: 0.768501\n",
      "[3]\tvalid_0's auc: 0.781382\tvalid_0's pr_auc: 0.780655\n",
      "[4]\tvalid_0's auc: 0.783227\tvalid_0's pr_auc: 0.781605\n",
      "[5]\tvalid_0's auc: 0.785818\tvalid_0's pr_auc: 0.784037\n",
      "[6]\tvalid_0's auc: 0.785845\tvalid_0's pr_auc: 0.784556\n",
      "[7]\tvalid_0's auc: 0.78684\tvalid_0's pr_auc: 0.78573\n",
      "[8]\tvalid_0's auc: 0.788376\tvalid_0's pr_auc: 0.786671\n",
      "[9]\tvalid_0's auc: 0.789364\tvalid_0's pr_auc: 0.787545\n",
      "[10]\tvalid_0's auc: 0.792334\tvalid_0's pr_auc: 0.788845\n",
      "[11]\tvalid_0's auc: 0.793372\tvalid_0's pr_auc: 0.78982\n",
      "[12]\tvalid_0's auc: 0.794715\tvalid_0's pr_auc: 0.790814\n",
      "[13]\tvalid_0's auc: 0.79521\tvalid_0's pr_auc: 0.790167\n",
      "[14]\tvalid_0's auc: 0.79634\tvalid_0's pr_auc: 0.790798\n",
      "[15]\tvalid_0's auc: 0.797389\tvalid_0's pr_auc: 0.785355\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.794715\tvalid_0's pr_auc: 0.790814\n",
      "======================================\n",
      "[LightGBM] [Info] Number of positive: 4828, number of negative: 7172\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4343\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 41\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.402333 -> initscore=-0.395752\n",
      "[LightGBM] [Info] Start training from score -0.395752\n",
      "[1]\tvalid_0's auc: 0.776638\tvalid_0's pr_auc: 0.306199\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[2]\tvalid_0's auc: 0.781385\tvalid_0's pr_auc: 0.315422\n",
      "[3]\tvalid_0's auc: 0.78475\tvalid_0's pr_auc: 0.297361\n",
      "[4]\tvalid_0's auc: 0.794344\tvalid_0's pr_auc: 0.276778\n",
      "[5]\tvalid_0's auc: 0.793041\tvalid_0's pr_auc: 0.275644\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.781385\tvalid_0's pr_auc: 0.315422\n",
      "======================================\n",
      "[LightGBM] [Info] Number of positive: 4718, number of negative: 7282\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4452\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 41\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393167 -> initscore=-0.434021\n",
      "[LightGBM] [Info] Start training from score -0.434021\n",
      "[1]\tvalid_0's auc: 0.745283\tvalid_0's pr_auc: 0.347311\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[2]\tvalid_0's auc: 0.756389\tvalid_0's pr_auc: 0.35936\n",
      "[3]\tvalid_0's auc: 0.758906\tvalid_0's pr_auc: 0.332203\n",
      "[4]\tvalid_0's auc: 0.761758\tvalid_0's pr_auc: 0.332344\n",
      "[5]\tvalid_0's auc: 0.763839\tvalid_0's pr_auc: 0.350639\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.756389\tvalid_0's pr_auc: 0.35936\n",
      "======================================\n",
      "[LightGBM] [Info] Number of positive: 4544, number of negative: 7456\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4462\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 41\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378667 -> initscore=-0.495211\n",
      "[LightGBM] [Info] Start training from score -0.495211\n",
      "[1]\tvalid_0's auc: 0.784892\tvalid_0's pr_auc: 0.531822\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[2]\tvalid_0's auc: 0.788493\tvalid_0's pr_auc: 0.52309\n",
      "[3]\tvalid_0's auc: 0.7952\tvalid_0's pr_auc: 0.524952\n",
      "[4]\tvalid_0's auc: 0.796227\tvalid_0's pr_auc: 0.525851\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.784892\tvalid_0's pr_auc: 0.531822\n",
      "======================================\n",
      "[LightGBM] [Info] Number of positive: 2277, number of negative: 9723\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4227\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 41\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.189750 -> initscore=-1.451635\n",
      "[LightGBM] [Info] Start training from score -1.451635\n",
      "[1]\tvalid_0's auc: 0.777077\tvalid_0's pr_auc: 0.970889\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "[2]\tvalid_0's auc: 0.788925\tvalid_0's pr_auc: 0.97234\n",
      "[3]\tvalid_0's auc: 0.787505\tvalid_0's pr_auc: 0.972317\n",
      "[4]\tvalid_0's auc: 0.790305\tvalid_0's pr_auc: 0.972753\n",
      "[5]\tvalid_0's auc: 0.793283\tvalid_0's pr_auc: 0.971849\n",
      "[6]\tvalid_0's auc: 0.79388\tvalid_0's pr_auc: 0.970336\n",
      "[7]\tvalid_0's auc: 0.795191\tvalid_0's pr_auc: 0.973339\n",
      "[8]\tvalid_0's auc: 0.796743\tvalid_0's pr_auc: 0.973506\n",
      "[9]\tvalid_0's auc: 0.796941\tvalid_0's pr_auc: 0.97348\n",
      "[10]\tvalid_0's auc: 0.800731\tvalid_0's pr_auc: 0.973952\n",
      "[11]\tvalid_0's auc: 0.800628\tvalid_0's pr_auc: 0.97386\n",
      "[12]\tvalid_0's auc: 0.802074\tvalid_0's pr_auc: 0.974225\n",
      "[13]\tvalid_0's auc: 0.803119\tvalid_0's pr_auc: 0.974318\n",
      "[14]\tvalid_0's auc: 0.803294\tvalid_0's pr_auc: 0.974313\n",
      "[15]\tvalid_0's auc: 0.804568\tvalid_0's pr_auc: 0.974233\n",
      "[16]\tvalid_0's auc: 0.807149\tvalid_0's pr_auc: 0.974521\n",
      "[17]\tvalid_0's auc: 0.807358\tvalid_0's pr_auc: 0.974535\n",
      "[18]\tvalid_0's auc: 0.808187\tvalid_0's pr_auc: 0.974665\n",
      "[19]\tvalid_0's auc: 0.808206\tvalid_0's pr_auc: 0.974663\n",
      "[20]\tvalid_0's auc: 0.807998\tvalid_0's pr_auc: 0.974673\n",
      "[21]\tvalid_0's auc: 0.808029\tvalid_0's pr_auc: 0.974711\n",
      "[22]\tvalid_0's auc: 0.808986\tvalid_0's pr_auc: 0.97489\n",
      "[23]\tvalid_0's auc: 0.809938\tvalid_0's pr_auc: 0.975093\n",
      "[24]\tvalid_0's auc: 0.809977\tvalid_0's pr_auc: 0.975186\n",
      "[25]\tvalid_0's auc: 0.809617\tvalid_0's pr_auc: 0.975175\n",
      "[26]\tvalid_0's auc: 0.81087\tvalid_0's pr_auc: 0.975462\n",
      "[27]\tvalid_0's auc: 0.811419\tvalid_0's pr_auc: 0.975468\n",
      "[28]\tvalid_0's auc: 0.811761\tvalid_0's pr_auc: 0.975482\n",
      "[29]\tvalid_0's auc: 0.812158\tvalid_0's pr_auc: 0.975473\n",
      "[30]\tvalid_0's auc: 0.812386\tvalid_0's pr_auc: 0.975545\n",
      "[31]\tvalid_0's auc: 0.812331\tvalid_0's pr_auc: 0.97553\n",
      "[32]\tvalid_0's auc: 0.812557\tvalid_0's pr_auc: 0.975456\n",
      "[33]\tvalid_0's auc: 0.812076\tvalid_0's pr_auc: 0.975315\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.812386\tvalid_0's pr_auc: 0.975545\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "PATH = '../data/'\n",
    "train_X = pd.read_csv(PATH+'train_X.csv')\n",
    "train_y = pd.read_csv(PATH+'label.csv')\n",
    "test_X = pd.read_csv(PATH+'test_X.csv')\n",
    "\n",
    "models = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "auc_scores = []\n",
    "threshold = 0.5\n",
    "# parameter 설정\n",
    "params= {'boosting_type' : 'gbdt',\n",
    "         'objective' : 'binary',\n",
    "         'metric' : 'auc',\n",
    "         'seed':1015\n",
    "        }\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state = 42)\n",
    "# 5 fold cross validation\n",
    "for train_idx, val_idx in k_fold.split(train_X):\n",
    "    \n",
    "    #split train, validation set\n",
    "    X = train_X.iloc[train_idx]\n",
    "    y = train_y.iloc[train_idx]\n",
    "    valid_x = train_X.iloc[val_idx]\n",
    "    valid_y = train_y.iloc[val_idx]\n",
    "    \n",
    "    d_train = lgb.Dataset(X,y)\n",
    "    d_val = lgb.Dataset(valid_x, valid_y)\n",
    "    \n",
    "    # run training\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set = d_train , \n",
    "        num_boost_round = 1000, # num_trees 와 똑같이 보면된다\n",
    "        valid_sets = d_val, \n",
    "        feval = f_pr_auc,  #customized evaluation function\n",
    "        # verbose_eval = 20 ,\n",
    "        early_stopping_rounds = 3\n",
    "    )\n",
    "    \n",
    "    # cal valid prediction\n",
    "    \n",
    "    valid_prob = model.predict(valid_x)\n",
    "    valid_pred = np.where(valid_prob > threshold,1,0)\n",
    "    \n",
    "    # cal scores\n",
    "    \n",
    "    recall = recall_score( valid_y, valid_pred)\n",
    "    precision = precision_score(valid_y, valid_pred)\n",
    "    auc_score = roc_auc_score(valid_y, valid_prob)\n",
    "    \n",
    "    # append scores\n",
    "    models.append(model)\n",
    "    recalls.append(recall)\n",
    "    precisions.append(precision)\n",
    "    auc_scores.append(auc_score)\n",
    "    \n",
    "    print('='*38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e6ee5-3aeb-4573-8ec8-f69458a267ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def funcSample():\n",
    "#     print('sample')\n",
    "# callable(funcSample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d31e22a-8747-4300-bd8a-50a0a7d59948",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Xgboost "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e07d058-6337-4a77-8aed-c14aa330558f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 훈련 모델 ver 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6ce93f-1dae-4d91-ac75-0bfe7a6603e4",
   "metadata": {},
   "source": [
    "- train_test_split 의 test_size를 20%\n",
    "- parameter\n",
    "    1. 'max_depth' : 3,\n",
    "    2. 'eta' : 0.01,\n",
    "    3. 'booster' :'gbtree',\n",
    "    4.  'eval_metric' : 'logloss'\n",
    "    5.   num_rounds = 400\n",
    "    6.   early_stopping_rounds= 100, \n",
    "    7.   evals = wlist \n",
    "           - 이건 학습할 데이터를 train 으로 명시해주고 평가할 데이터를 eval를 명시해줘서 넣는것\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bb6cf73b-88f6-477a-a89c-457eda4e17f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e7b53f3e-7da8-426b-b254-14824fa660dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 42), (3000, 1))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val , y_train ,y_val = train_test_split(\n",
    "    train_X, train_y, test_size = 0.2 , random_state= 42)\n",
    "\n",
    "# xgb.DMatrix(train_x,train_y)\n",
    "X_train.shape , y_train.shape\n",
    "X_val.shape , y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "259071a0-800a-4057-b9b1-9dbb1566a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = xgb.DMatrix(X_train,y_train)\n",
    "d_val = xgb.DMatrix(X_val, y_val) \n",
    "d_test = xgb.DMatrix(test_X)\n",
    "# Dmatrix는 XGBoost python wrapper(이게 정확히 무슨뜻인지는모름) 데이터셋을 만드는 메소드\n",
    "# xgb_model = xgb.XGBClassifier(silent=0)\n",
    "# print(xgb.XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "140b9fd7-53fc-41d7-ac1d-ad189a4a4e87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.68973\teval-logloss:0.69068\n",
      "[1]\ttrain-logloss:0.68637\teval-logloss:0.68828\n",
      "[2]\ttrain-logloss:0.68308\teval-logloss:0.68594\n",
      "[3]\ttrain-logloss:0.67985\teval-logloss:0.68365\n",
      "[4]\ttrain-logloss:0.67669\teval-logloss:0.68143\n",
      "[5]\ttrain-logloss:0.67359\teval-logloss:0.67925\n",
      "[6]\ttrain-logloss:0.67054\teval-logloss:0.67714\n",
      "[7]\ttrain-logloss:0.66755\teval-logloss:0.67505\n",
      "[8]\ttrain-logloss:0.66463\teval-logloss:0.67301\n",
      "[9]\ttrain-logloss:0.66175\teval-logloss:0.67102\n",
      "[10]\ttrain-logloss:0.65893\teval-logloss:0.66908\n",
      "[11]\ttrain-logloss:0.65613\teval-logloss:0.66718\n",
      "[12]\ttrain-logloss:0.65338\teval-logloss:0.66533\n",
      "[13]\ttrain-logloss:0.65068\teval-logloss:0.66352\n",
      "[14]\ttrain-logloss:0.64804\teval-logloss:0.66177\n",
      "[15]\ttrain-logloss:0.64545\teval-logloss:0.66004\n",
      "[16]\ttrain-logloss:0.64290\teval-logloss:0.65837\n",
      "[17]\ttrain-logloss:0.64040\teval-logloss:0.65672\n",
      "[18]\ttrain-logloss:0.63795\teval-logloss:0.65510\n",
      "[19]\ttrain-logloss:0.63553\teval-logloss:0.65353\n",
      "[20]\ttrain-logloss:0.63317\teval-logloss:0.65198\n",
      "[21]\ttrain-logloss:0.63085\teval-logloss:0.65045\n",
      "[22]\ttrain-logloss:0.62857\teval-logloss:0.64900\n",
      "[23]\ttrain-logloss:0.62632\teval-logloss:0.64754\n",
      "[24]\ttrain-logloss:0.62412\teval-logloss:0.64612\n",
      "[25]\ttrain-logloss:0.62196\teval-logloss:0.64474\n",
      "[26]\ttrain-logloss:0.61983\teval-logloss:0.64339\n",
      "[27]\ttrain-logloss:0.61774\teval-logloss:0.64204\n",
      "[28]\ttrain-logloss:0.61568\teval-logloss:0.64075\n",
      "[29]\ttrain-logloss:0.61367\teval-logloss:0.63944\n",
      "[30]\ttrain-logloss:0.61168\teval-logloss:0.63820\n",
      "[31]\ttrain-logloss:0.60974\teval-logloss:0.63697\n",
      "[32]\ttrain-logloss:0.60781\teval-logloss:0.63578\n",
      "[33]\ttrain-logloss:0.60592\teval-logloss:0.63461\n",
      "[34]\ttrain-logloss:0.60407\teval-logloss:0.63350\n",
      "[35]\ttrain-logloss:0.60225\teval-logloss:0.63237\n",
      "[36]\ttrain-logloss:0.60045\teval-logloss:0.63127\n",
      "[37]\ttrain-logloss:0.59869\teval-logloss:0.63020\n",
      "[38]\ttrain-logloss:0.59694\teval-logloss:0.62915\n",
      "[39]\ttrain-logloss:0.59523\teval-logloss:0.62811\n",
      "[40]\ttrain-logloss:0.59356\teval-logloss:0.62710\n",
      "[41]\ttrain-logloss:0.59190\teval-logloss:0.62613\n",
      "[42]\ttrain-logloss:0.59028\teval-logloss:0.62516\n",
      "[43]\ttrain-logloss:0.58868\teval-logloss:0.62424\n",
      "[44]\ttrain-logloss:0.58711\teval-logloss:0.62333\n",
      "[45]\ttrain-logloss:0.58557\teval-logloss:0.62247\n",
      "[46]\ttrain-logloss:0.58405\teval-logloss:0.62161\n",
      "[47]\ttrain-logloss:0.58256\teval-logloss:0.62073\n",
      "[48]\ttrain-logloss:0.58106\teval-logloss:0.61989\n",
      "[49]\ttrain-logloss:0.57962\teval-logloss:0.61909\n",
      "[50]\ttrain-logloss:0.57819\teval-logloss:0.61831\n",
      "[51]\ttrain-logloss:0.57679\teval-logloss:0.61750\n",
      "[52]\ttrain-logloss:0.57541\teval-logloss:0.61675\n",
      "[53]\ttrain-logloss:0.57405\teval-logloss:0.61599\n",
      "[54]\ttrain-logloss:0.57271\teval-logloss:0.61527\n",
      "[55]\ttrain-logloss:0.57140\teval-logloss:0.61458\n",
      "[56]\ttrain-logloss:0.57011\teval-logloss:0.61389\n",
      "[57]\ttrain-logloss:0.56883\teval-logloss:0.61324\n",
      "[58]\ttrain-logloss:0.56758\teval-logloss:0.61257\n",
      "[59]\ttrain-logloss:0.56634\teval-logloss:0.61190\n",
      "[60]\ttrain-logloss:0.56512\teval-logloss:0.61123\n",
      "[61]\ttrain-logloss:0.56392\teval-logloss:0.61064\n",
      "[62]\ttrain-logloss:0.56275\teval-logloss:0.61004\n",
      "[63]\ttrain-logloss:0.56159\teval-logloss:0.60944\n",
      "[64]\ttrain-logloss:0.56043\teval-logloss:0.60883\n",
      "[65]\ttrain-logloss:0.55930\teval-logloss:0.60824\n",
      "[66]\ttrain-logloss:0.55819\teval-logloss:0.60768\n",
      "[67]\ttrain-logloss:0.55710\teval-logloss:0.60714\n",
      "[68]\ttrain-logloss:0.55603\teval-logloss:0.60658\n",
      "[69]\ttrain-logloss:0.55494\teval-logloss:0.60604\n",
      "[70]\ttrain-logloss:0.55390\teval-logloss:0.60552\n",
      "[71]\ttrain-logloss:0.55287\teval-logloss:0.60501\n",
      "[72]\ttrain-logloss:0.55186\teval-logloss:0.60454\n",
      "[73]\ttrain-logloss:0.55087\teval-logloss:0.60405\n",
      "[74]\ttrain-logloss:0.54985\teval-logloss:0.60356\n",
      "[75]\ttrain-logloss:0.54889\teval-logloss:0.60312\n",
      "[76]\ttrain-logloss:0.54794\teval-logloss:0.60267\n",
      "[77]\ttrain-logloss:0.54698\teval-logloss:0.60220\n",
      "[78]\ttrain-logloss:0.54605\teval-logloss:0.60177\n",
      "[79]\ttrain-logloss:0.54515\teval-logloss:0.60133\n",
      "[80]\ttrain-logloss:0.54425\teval-logloss:0.60092\n",
      "[81]\ttrain-logloss:0.54336\teval-logloss:0.60050\n",
      "[82]\ttrain-logloss:0.54250\teval-logloss:0.60009\n",
      "[83]\ttrain-logloss:0.54163\teval-logloss:0.59966\n",
      "[84]\ttrain-logloss:0.54078\teval-logloss:0.59927\n",
      "[85]\ttrain-logloss:0.53996\teval-logloss:0.59889\n",
      "[86]\ttrain-logloss:0.53913\teval-logloss:0.59857\n",
      "[87]\ttrain-logloss:0.53832\teval-logloss:0.59823\n",
      "[88]\ttrain-logloss:0.53752\teval-logloss:0.59784\n",
      "[89]\ttrain-logloss:0.53673\teval-logloss:0.59748\n",
      "[90]\ttrain-logloss:0.53595\teval-logloss:0.59715\n",
      "[91]\ttrain-logloss:0.53519\teval-logloss:0.59681\n",
      "[92]\ttrain-logloss:0.53443\teval-logloss:0.59652\n",
      "[93]\ttrain-logloss:0.53369\teval-logloss:0.59619\n",
      "[94]\ttrain-logloss:0.53296\teval-logloss:0.59588\n",
      "[95]\ttrain-logloss:0.53220\teval-logloss:0.59554\n",
      "[96]\ttrain-logloss:0.53149\teval-logloss:0.59524\n",
      "[97]\ttrain-logloss:0.53079\teval-logloss:0.59495\n",
      "[98]\ttrain-logloss:0.53009\teval-logloss:0.59471\n",
      "[99]\ttrain-logloss:0.52941\teval-logloss:0.59442\n",
      "[100]\ttrain-logloss:0.52873\teval-logloss:0.59420\n",
      "[101]\ttrain-logloss:0.52804\teval-logloss:0.59387\n",
      "[102]\ttrain-logloss:0.52739\teval-logloss:0.59361\n",
      "[103]\ttrain-logloss:0.52675\teval-logloss:0.59335\n",
      "[104]\ttrain-logloss:0.52610\teval-logloss:0.59309\n",
      "[105]\ttrain-logloss:0.52547\teval-logloss:0.59283\n",
      "[106]\ttrain-logloss:0.52486\teval-logloss:0.59263\n",
      "[107]\ttrain-logloss:0.52424\teval-logloss:0.59239\n",
      "[108]\ttrain-logloss:0.52363\teval-logloss:0.59214\n",
      "[109]\ttrain-logloss:0.52301\teval-logloss:0.59191\n",
      "[110]\ttrain-logloss:0.52242\teval-logloss:0.59170\n",
      "[111]\ttrain-logloss:0.52185\teval-logloss:0.59148\n",
      "[112]\ttrain-logloss:0.52128\teval-logloss:0.59125\n",
      "[113]\ttrain-logloss:0.52069\teval-logloss:0.59104\n",
      "[114]\ttrain-logloss:0.52011\teval-logloss:0.59081\n",
      "[115]\ttrain-logloss:0.51956\teval-logloss:0.59063\n",
      "[116]\ttrain-logloss:0.51898\teval-logloss:0.59037\n",
      "[117]\ttrain-logloss:0.51844\teval-logloss:0.59018\n",
      "[118]\ttrain-logloss:0.51790\teval-logloss:0.59001\n",
      "[119]\ttrain-logloss:0.51738\teval-logloss:0.58983\n",
      "[120]\ttrain-logloss:0.51687\teval-logloss:0.58964\n",
      "[121]\ttrain-logloss:0.51636\teval-logloss:0.58947\n",
      "[122]\ttrain-logloss:0.51584\teval-logloss:0.58932\n",
      "[123]\ttrain-logloss:0.51536\teval-logloss:0.58917\n",
      "[124]\ttrain-logloss:0.51483\teval-logloss:0.58895\n",
      "[125]\ttrain-logloss:0.51434\teval-logloss:0.58882\n",
      "[126]\ttrain-logloss:0.51383\teval-logloss:0.58859\n",
      "[127]\ttrain-logloss:0.51334\teval-logloss:0.58843\n",
      "[128]\ttrain-logloss:0.51288\teval-logloss:0.58829\n",
      "[129]\ttrain-logloss:0.51242\teval-logloss:0.58813\n",
      "[130]\ttrain-logloss:0.51195\teval-logloss:0.58799\n",
      "[131]\ttrain-logloss:0.51146\teval-logloss:0.58779\n",
      "[132]\ttrain-logloss:0.51104\teval-logloss:0.58768\n",
      "[133]\ttrain-logloss:0.51057\teval-logloss:0.58749\n",
      "[134]\ttrain-logloss:0.51014\teval-logloss:0.58739\n",
      "[135]\ttrain-logloss:0.50971\teval-logloss:0.58724\n",
      "[136]\ttrain-logloss:0.50930\teval-logloss:0.58710\n",
      "[137]\ttrain-logloss:0.50885\teval-logloss:0.58693\n",
      "[138]\ttrain-logloss:0.50842\teval-logloss:0.58678\n",
      "[139]\ttrain-logloss:0.50801\teval-logloss:0.58668\n",
      "[140]\ttrain-logloss:0.50762\teval-logloss:0.58659\n",
      "[141]\ttrain-logloss:0.50720\teval-logloss:0.58643\n",
      "[142]\ttrain-logloss:0.50679\teval-logloss:0.58627\n",
      "[143]\ttrain-logloss:0.50639\teval-logloss:0.58615\n",
      "[144]\ttrain-logloss:0.50600\teval-logloss:0.58606\n",
      "[145]\ttrain-logloss:0.50564\teval-logloss:0.58597\n",
      "[146]\ttrain-logloss:0.50524\teval-logloss:0.58582\n",
      "[147]\ttrain-logloss:0.50487\teval-logloss:0.58574\n",
      "[148]\ttrain-logloss:0.50451\teval-logloss:0.58566\n",
      "[149]\ttrain-logloss:0.50413\teval-logloss:0.58552\n",
      "[150]\ttrain-logloss:0.50376\teval-logloss:0.58540\n",
      "[151]\ttrain-logloss:0.50343\teval-logloss:0.58534\n",
      "[152]\ttrain-logloss:0.50308\teval-logloss:0.58525\n",
      "[153]\ttrain-logloss:0.50274\teval-logloss:0.58515\n",
      "[154]\ttrain-logloss:0.50238\teval-logloss:0.58501\n",
      "[155]\ttrain-logloss:0.50201\teval-logloss:0.58495\n",
      "[156]\ttrain-logloss:0.50166\teval-logloss:0.58490\n",
      "[157]\ttrain-logloss:0.50135\teval-logloss:0.58482\n",
      "[158]\ttrain-logloss:0.50101\teval-logloss:0.58476\n",
      "[159]\ttrain-logloss:0.50068\teval-logloss:0.58469\n",
      "[160]\ttrain-logloss:0.50036\teval-logloss:0.58458\n",
      "[161]\ttrain-logloss:0.50004\teval-logloss:0.58451\n",
      "[162]\ttrain-logloss:0.49971\teval-logloss:0.58442\n",
      "[163]\ttrain-logloss:0.49940\teval-logloss:0.58435\n",
      "[164]\ttrain-logloss:0.49908\teval-logloss:0.58431\n",
      "[165]\ttrain-logloss:0.49878\teval-logloss:0.58425\n",
      "[166]\ttrain-logloss:0.49847\teval-logloss:0.58418\n",
      "[167]\ttrain-logloss:0.49817\teval-logloss:0.58411\n",
      "[168]\ttrain-logloss:0.49784\teval-logloss:0.58398\n",
      "[169]\ttrain-logloss:0.49753\teval-logloss:0.58387\n",
      "[170]\ttrain-logloss:0.49723\teval-logloss:0.58383\n",
      "[171]\ttrain-logloss:0.49695\teval-logloss:0.58377\n",
      "[172]\ttrain-logloss:0.49664\teval-logloss:0.58364\n",
      "[173]\ttrain-logloss:0.49635\teval-logloss:0.58360\n",
      "[174]\ttrain-logloss:0.49605\teval-logloss:0.58354\n",
      "[175]\ttrain-logloss:0.49577\teval-logloss:0.58346\n",
      "[176]\ttrain-logloss:0.49547\teval-logloss:0.58337\n",
      "[177]\ttrain-logloss:0.49520\teval-logloss:0.58330\n",
      "[178]\ttrain-logloss:0.49491\teval-logloss:0.58325\n",
      "[179]\ttrain-logloss:0.49463\teval-logloss:0.58316\n",
      "[180]\ttrain-logloss:0.49436\teval-logloss:0.58311\n",
      "[181]\ttrain-logloss:0.49408\teval-logloss:0.58303\n",
      "[182]\ttrain-logloss:0.49381\teval-logloss:0.58294\n",
      "[183]\ttrain-logloss:0.49355\teval-logloss:0.58289\n",
      "[184]\ttrain-logloss:0.49329\teval-logloss:0.58284\n",
      "[185]\ttrain-logloss:0.49302\teval-logloss:0.58276\n",
      "[186]\ttrain-logloss:0.49277\teval-logloss:0.58274\n",
      "[187]\ttrain-logloss:0.49252\teval-logloss:0.58269\n",
      "[188]\ttrain-logloss:0.49226\teval-logloss:0.58264\n",
      "[189]\ttrain-logloss:0.49199\teval-logloss:0.58254\n",
      "[190]\ttrain-logloss:0.49174\teval-logloss:0.58247\n",
      "[191]\ttrain-logloss:0.49150\teval-logloss:0.58242\n",
      "[192]\ttrain-logloss:0.49125\teval-logloss:0.58235\n",
      "[193]\ttrain-logloss:0.49100\teval-logloss:0.58230\n",
      "[194]\ttrain-logloss:0.49076\teval-logloss:0.58226\n",
      "[195]\ttrain-logloss:0.49054\teval-logloss:0.58223\n",
      "[196]\ttrain-logloss:0.49029\teval-logloss:0.58213\n",
      "[197]\ttrain-logloss:0.49006\teval-logloss:0.58209\n",
      "[198]\ttrain-logloss:0.48984\teval-logloss:0.58206\n",
      "[199]\ttrain-logloss:0.48960\teval-logloss:0.58196\n",
      "[200]\ttrain-logloss:0.48937\teval-logloss:0.58192\n",
      "[201]\ttrain-logloss:0.48915\teval-logloss:0.58192\n",
      "[202]\ttrain-logloss:0.48893\teval-logloss:0.58188\n",
      "[203]\ttrain-logloss:0.48871\teval-logloss:0.58184\n",
      "[204]\ttrain-logloss:0.48850\teval-logloss:0.58181\n",
      "[205]\ttrain-logloss:0.48826\teval-logloss:0.58174\n",
      "[206]\ttrain-logloss:0.48803\teval-logloss:0.58165\n",
      "[207]\ttrain-logloss:0.48782\teval-logloss:0.58156\n",
      "[208]\ttrain-logloss:0.48760\teval-logloss:0.58155\n",
      "[209]\ttrain-logloss:0.48740\teval-logloss:0.58151\n",
      "[210]\ttrain-logloss:0.48720\teval-logloss:0.58149\n",
      "[211]\ttrain-logloss:0.48698\teval-logloss:0.58147\n",
      "[212]\ttrain-logloss:0.48679\teval-logloss:0.58143\n",
      "[213]\ttrain-logloss:0.48659\teval-logloss:0.58139\n",
      "[214]\ttrain-logloss:0.48638\teval-logloss:0.58130\n",
      "[215]\ttrain-logloss:0.48617\teval-logloss:0.58125\n",
      "[216]\ttrain-logloss:0.48597\teval-logloss:0.58122\n",
      "[217]\ttrain-logloss:0.48579\teval-logloss:0.58120\n",
      "[218]\ttrain-logloss:0.48559\teval-logloss:0.58116\n",
      "[219]\ttrain-logloss:0.48539\teval-logloss:0.58107\n",
      "[220]\ttrain-logloss:0.48519\teval-logloss:0.58103\n",
      "[221]\ttrain-logloss:0.48501\teval-logloss:0.58099\n",
      "[222]\ttrain-logloss:0.48481\teval-logloss:0.58091\n",
      "[223]\ttrain-logloss:0.48460\teval-logloss:0.58080\n",
      "[224]\ttrain-logloss:0.48441\teval-logloss:0.58076\n",
      "[225]\ttrain-logloss:0.48423\teval-logloss:0.58073\n",
      "[226]\ttrain-logloss:0.48404\teval-logloss:0.58072\n",
      "[227]\ttrain-logloss:0.48387\teval-logloss:0.58070\n",
      "[228]\ttrain-logloss:0.48367\teval-logloss:0.58061\n",
      "[229]\ttrain-logloss:0.48350\teval-logloss:0.58057\n",
      "[230]\ttrain-logloss:0.48331\teval-logloss:0.58056\n",
      "[231]\ttrain-logloss:0.48315\teval-logloss:0.58054\n",
      "[232]\ttrain-logloss:0.48296\teval-logloss:0.58043\n",
      "[233]\ttrain-logloss:0.48278\teval-logloss:0.58040\n",
      "[234]\ttrain-logloss:0.48261\teval-logloss:0.58036\n",
      "[235]\ttrain-logloss:0.48242\teval-logloss:0.58032\n",
      "[236]\ttrain-logloss:0.48227\teval-logloss:0.58030\n",
      "[237]\ttrain-logloss:0.48211\teval-logloss:0.58031\n",
      "[238]\ttrain-logloss:0.48191\teval-logloss:0.58025\n",
      "[239]\ttrain-logloss:0.48173\teval-logloss:0.58017\n",
      "[240]\ttrain-logloss:0.48156\teval-logloss:0.58013\n",
      "[241]\ttrain-logloss:0.48139\teval-logloss:0.58012\n",
      "[242]\ttrain-logloss:0.48123\teval-logloss:0.58012\n",
      "[243]\ttrain-logloss:0.48108\teval-logloss:0.58010\n",
      "[244]\ttrain-logloss:0.48089\teval-logloss:0.58004\n",
      "[245]\ttrain-logloss:0.48072\teval-logloss:0.57994\n",
      "[246]\ttrain-logloss:0.48056\teval-logloss:0.57991\n",
      "[247]\ttrain-logloss:0.48040\teval-logloss:0.57992\n",
      "[248]\ttrain-logloss:0.48022\teval-logloss:0.57987\n",
      "[249]\ttrain-logloss:0.48008\teval-logloss:0.57985\n",
      "[250]\ttrain-logloss:0.47990\teval-logloss:0.57980\n",
      "[251]\ttrain-logloss:0.47976\teval-logloss:0.57979\n",
      "[252]\ttrain-logloss:0.47959\teval-logloss:0.57974\n",
      "[253]\ttrain-logloss:0.47944\teval-logloss:0.57972\n",
      "[254]\ttrain-logloss:0.47929\teval-logloss:0.57971\n",
      "[255]\ttrain-logloss:0.47914\teval-logloss:0.57967\n",
      "[256]\ttrain-logloss:0.47899\teval-logloss:0.57964\n",
      "[257]\ttrain-logloss:0.47883\teval-logloss:0.57955\n",
      "[258]\ttrain-logloss:0.47869\teval-logloss:0.57955\n",
      "[259]\ttrain-logloss:0.47856\teval-logloss:0.57954\n",
      "[260]\ttrain-logloss:0.47841\teval-logloss:0.57952\n",
      "[261]\ttrain-logloss:0.47825\teval-logloss:0.57948\n",
      "[262]\ttrain-logloss:0.47811\teval-logloss:0.57944\n",
      "[263]\ttrain-logloss:0.47793\teval-logloss:0.57937\n",
      "[264]\ttrain-logloss:0.47778\teval-logloss:0.57932\n",
      "[265]\ttrain-logloss:0.47763\teval-logloss:0.57929\n",
      "[266]\ttrain-logloss:0.47751\teval-logloss:0.57927\n",
      "[267]\ttrain-logloss:0.47737\teval-logloss:0.57928\n",
      "[268]\ttrain-logloss:0.47724\teval-logloss:0.57927\n",
      "[269]\ttrain-logloss:0.47705\teval-logloss:0.57915\n",
      "[270]\ttrain-logloss:0.47690\teval-logloss:0.57913\n",
      "[271]\ttrain-logloss:0.47675\teval-logloss:0.57905\n",
      "[272]\ttrain-logloss:0.47661\teval-logloss:0.57900\n",
      "[273]\ttrain-logloss:0.47648\teval-logloss:0.57899\n",
      "[274]\ttrain-logloss:0.47634\teval-logloss:0.57896\n",
      "[275]\ttrain-logloss:0.47622\teval-logloss:0.57895\n",
      "[276]\ttrain-logloss:0.47609\teval-logloss:0.57896\n",
      "[277]\ttrain-logloss:0.47595\teval-logloss:0.57893\n",
      "[278]\ttrain-logloss:0.47578\teval-logloss:0.57882\n",
      "[279]\ttrain-logloss:0.47565\teval-logloss:0.57878\n",
      "[280]\ttrain-logloss:0.47552\teval-logloss:0.57877\n",
      "[281]\ttrain-logloss:0.47538\teval-logloss:0.57874\n",
      "[282]\ttrain-logloss:0.47525\teval-logloss:0.57870\n",
      "[283]\ttrain-logloss:0.47509\teval-logloss:0.57861\n",
      "[284]\ttrain-logloss:0.47498\teval-logloss:0.57861\n",
      "[285]\ttrain-logloss:0.47485\teval-logloss:0.57857\n",
      "[286]\ttrain-logloss:0.47473\teval-logloss:0.57856\n",
      "[287]\ttrain-logloss:0.47460\teval-logloss:0.57852\n",
      "[288]\ttrain-logloss:0.47444\teval-logloss:0.57843\n",
      "[289]\ttrain-logloss:0.47431\teval-logloss:0.57837\n",
      "[290]\ttrain-logloss:0.47417\teval-logloss:0.57832\n",
      "[291]\ttrain-logloss:0.47406\teval-logloss:0.57831\n",
      "[292]\ttrain-logloss:0.47391\teval-logloss:0.57823\n",
      "[293]\ttrain-logloss:0.47379\teval-logloss:0.57819\n",
      "[294]\ttrain-logloss:0.47364\teval-logloss:0.57808\n",
      "[295]\ttrain-logloss:0.47351\teval-logloss:0.57806\n",
      "[296]\ttrain-logloss:0.47338\teval-logloss:0.57801\n",
      "[297]\ttrain-logloss:0.47326\teval-logloss:0.57798\n",
      "[298]\ttrain-logloss:0.47316\teval-logloss:0.57798\n",
      "[299]\ttrain-logloss:0.47304\teval-logloss:0.57795\n",
      "[300]\ttrain-logloss:0.47291\teval-logloss:0.57790\n",
      "[301]\ttrain-logloss:0.47280\teval-logloss:0.57791\n",
      "[302]\ttrain-logloss:0.47266\teval-logloss:0.57782\n",
      "[303]\ttrain-logloss:0.47254\teval-logloss:0.57777\n",
      "[304]\ttrain-logloss:0.47242\teval-logloss:0.57772\n",
      "[305]\ttrain-logloss:0.47230\teval-logloss:0.57767\n",
      "[306]\ttrain-logloss:0.47218\teval-logloss:0.57762\n",
      "[307]\ttrain-logloss:0.47207\teval-logloss:0.57760\n",
      "[308]\ttrain-logloss:0.47193\teval-logloss:0.57752\n",
      "[309]\ttrain-logloss:0.47182\teval-logloss:0.57750\n",
      "[310]\ttrain-logloss:0.47170\teval-logloss:0.57747\n",
      "[311]\ttrain-logloss:0.47161\teval-logloss:0.57748\n",
      "[312]\ttrain-logloss:0.47148\teval-logloss:0.57739\n",
      "[313]\ttrain-logloss:0.47136\teval-logloss:0.57734\n",
      "[314]\ttrain-logloss:0.47125\teval-logloss:0.57731\n",
      "[315]\ttrain-logloss:0.47114\teval-logloss:0.57728\n",
      "[316]\ttrain-logloss:0.47103\teval-logloss:0.57726\n",
      "[317]\ttrain-logloss:0.47092\teval-logloss:0.57725\n",
      "[318]\ttrain-logloss:0.47081\teval-logloss:0.57722\n",
      "[319]\ttrain-logloss:0.47069\teval-logloss:0.57712\n",
      "[320]\ttrain-logloss:0.47058\teval-logloss:0.57712\n",
      "[321]\ttrain-logloss:0.47047\teval-logloss:0.57708\n",
      "[322]\ttrain-logloss:0.47036\teval-logloss:0.57704\n",
      "[323]\ttrain-logloss:0.47028\teval-logloss:0.57705\n",
      "[324]\ttrain-logloss:0.47018\teval-logloss:0.57703\n",
      "[325]\ttrain-logloss:0.47006\teval-logloss:0.57695\n",
      "[326]\ttrain-logloss:0.46996\teval-logloss:0.57693\n",
      "[327]\ttrain-logloss:0.46985\teval-logloss:0.57688\n",
      "[328]\ttrain-logloss:0.46975\teval-logloss:0.57687\n",
      "[329]\ttrain-logloss:0.46963\teval-logloss:0.57678\n",
      "[330]\ttrain-logloss:0.46953\teval-logloss:0.57676\n",
      "[331]\ttrain-logloss:0.46943\teval-logloss:0.57673\n",
      "[332]\ttrain-logloss:0.46932\teval-logloss:0.57670\n",
      "[333]\ttrain-logloss:0.46923\teval-logloss:0.57669\n",
      "[334]\ttrain-logloss:0.46912\teval-logloss:0.57665\n",
      "[335]\ttrain-logloss:0.46901\teval-logloss:0.57657\n",
      "[336]\ttrain-logloss:0.46891\teval-logloss:0.57655\n",
      "[337]\ttrain-logloss:0.46882\teval-logloss:0.57654\n",
      "[338]\ttrain-logloss:0.46873\teval-logloss:0.57651\n",
      "[339]\ttrain-logloss:0.46864\teval-logloss:0.57649\n",
      "[340]\ttrain-logloss:0.46854\teval-logloss:0.57646\n",
      "[341]\ttrain-logloss:0.46844\teval-logloss:0.57644\n",
      "[342]\ttrain-logloss:0.46836\teval-logloss:0.57642\n",
      "[343]\ttrain-logloss:0.46825\teval-logloss:0.57634\n",
      "[344]\ttrain-logloss:0.46816\teval-logloss:0.57632\n",
      "[345]\ttrain-logloss:0.46806\teval-logloss:0.57629\n",
      "[346]\ttrain-logloss:0.46797\teval-logloss:0.57626\n",
      "[347]\ttrain-logloss:0.46787\teval-logloss:0.57623\n",
      "[348]\ttrain-logloss:0.46779\teval-logloss:0.57621\n",
      "[349]\ttrain-logloss:0.46771\teval-logloss:0.57621\n",
      "[350]\ttrain-logloss:0.46760\teval-logloss:0.57613\n",
      "[351]\ttrain-logloss:0.46751\teval-logloss:0.57610\n",
      "[352]\ttrain-logloss:0.46742\teval-logloss:0.57608\n",
      "[353]\ttrain-logloss:0.46734\teval-logloss:0.57605\n",
      "[354]\ttrain-logloss:0.46724\teval-logloss:0.57602\n",
      "[355]\ttrain-logloss:0.46715\teval-logloss:0.57601\n",
      "[356]\ttrain-logloss:0.46706\teval-logloss:0.57599\n",
      "[357]\ttrain-logloss:0.46697\teval-logloss:0.57596\n",
      "[358]\ttrain-logloss:0.46690\teval-logloss:0.57594\n",
      "[359]\ttrain-logloss:0.46681\teval-logloss:0.57591\n",
      "[360]\ttrain-logloss:0.46671\teval-logloss:0.57584\n",
      "[361]\ttrain-logloss:0.46663\teval-logloss:0.57583\n",
      "[362]\ttrain-logloss:0.46656\teval-logloss:0.57581\n",
      "[363]\ttrain-logloss:0.46647\teval-logloss:0.57578\n",
      "[364]\ttrain-logloss:0.46639\teval-logloss:0.57579\n",
      "[365]\ttrain-logloss:0.46630\teval-logloss:0.57574\n",
      "[366]\ttrain-logloss:0.46621\teval-logloss:0.57572\n",
      "[367]\ttrain-logloss:0.46613\teval-logloss:0.57570\n",
      "[368]\ttrain-logloss:0.46604\teval-logloss:0.57567\n",
      "[369]\ttrain-logloss:0.46596\teval-logloss:0.57566\n",
      "[370]\ttrain-logloss:0.46589\teval-logloss:0.57564\n",
      "[371]\ttrain-logloss:0.46582\teval-logloss:0.57562\n",
      "[372]\ttrain-logloss:0.46575\teval-logloss:0.57557\n",
      "[373]\ttrain-logloss:0.46565\teval-logloss:0.57553\n",
      "[374]\ttrain-logloss:0.46557\teval-logloss:0.57550\n",
      "[375]\ttrain-logloss:0.46547\teval-logloss:0.57545\n",
      "[376]\ttrain-logloss:0.46539\teval-logloss:0.57544\n",
      "[377]\ttrain-logloss:0.46531\teval-logloss:0.57540\n",
      "[378]\ttrain-logloss:0.46524\teval-logloss:0.57538\n",
      "[379]\ttrain-logloss:0.46518\teval-logloss:0.57540\n",
      "[380]\ttrain-logloss:0.46511\teval-logloss:0.57538\n",
      "[381]\ttrain-logloss:0.46501\teval-logloss:0.57533\n",
      "[382]\ttrain-logloss:0.46493\teval-logloss:0.57531\n",
      "[383]\ttrain-logloss:0.46484\teval-logloss:0.57527\n",
      "[384]\ttrain-logloss:0.46475\teval-logloss:0.57521\n",
      "[385]\ttrain-logloss:0.46466\teval-logloss:0.57515\n",
      "[386]\ttrain-logloss:0.46460\teval-logloss:0.57512\n",
      "[387]\ttrain-logloss:0.46452\teval-logloss:0.57509\n",
      "[388]\ttrain-logloss:0.46444\teval-logloss:0.57506\n",
      "[389]\ttrain-logloss:0.46436\teval-logloss:0.57503\n",
      "[390]\ttrain-logloss:0.46427\teval-logloss:0.57498\n",
      "[391]\ttrain-logloss:0.46422\teval-logloss:0.57498\n",
      "[392]\ttrain-logloss:0.46415\teval-logloss:0.57497\n",
      "[393]\ttrain-logloss:0.46409\teval-logloss:0.57495\n",
      "[394]\ttrain-logloss:0.46404\teval-logloss:0.57494\n",
      "[395]\ttrain-logloss:0.46397\teval-logloss:0.57491\n",
      "[396]\ttrain-logloss:0.46389\teval-logloss:0.57492\n",
      "[397]\ttrain-logloss:0.46381\teval-logloss:0.57487\n",
      "[398]\ttrain-logloss:0.46376\teval-logloss:0.57487\n",
      "[399]\ttrain-logloss:0.46369\teval-logloss:0.57484\n"
     ]
    }
   ],
   "source": [
    "# params = {\n",
    "#     'booster' :'gbtree',\n",
    "#     'silent' : 0,\n",
    "#     'nthread': 10\n",
    "# }\n",
    "\n",
    "params = {\n",
    "    'max_depth' : 3,\n",
    "    'eta' : 0.01,\n",
    "    'booster' :'gbtree',\n",
    "    'eval_metric' : 'logloss'\n",
    "}\n",
    "num_rounds = 400\n",
    "wlist = [(d_train,'train'),(d_val,'eval')]\n",
    "xgb_model = xgb.train(params =params,dtrain = d_train , num_boost_round = num_rounds,\n",
    "         early_stopping_rounds= 100, evals = wlist)\n",
    "# print(\"훈련 세트 정확도 : {:.3f}\".format(xgb_model.score(X_train, y_train)))\n",
    "# print(\"validation 세트 정확도 : {:.3f}\".format(xgb_model.score(X_val, y_val)))\n",
    "# xgb_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b678707a-cac0-415e-b363-40d20cb20bdf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 훈련 ver 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b366568b-f9f9-4e21-a97f-b7e033e73531",
   "metadata": {},
   "source": [
    "- train_test_split 의 test_size를 30%\n",
    "- parameter\n",
    "    1. 'max_depth' : 3,\n",
    "    2. 'eta' : 0.01,\n",
    "    3. 'booster' :'gbtree',\n",
    "    4.  'eval_metric' : 'logloss'\n",
    "    5.   num_rounds = 400\n",
    "    6.   early_stopping_rounds= 100, \n",
    "    7.   evals = wlist \n",
    "    훈련 ver1 과 parameter는 같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b47fd8-eb5d-4d49-8cd9-09882153cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "760d43c7-a4b0-4935-81f2-ac1d596a3427",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val , y_train ,y_val = train_test_split(\n",
    "    train_X, train_y, test_size = 0.3 , random_state= 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30139c7d-f660-4068-a2fe-719d37e0611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train,y_train)\n",
    "dval = xgb.DMatrix(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d1d1f41-bbf7-483e-9bac-3f19e3fdca90",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.69011\teval-logloss:0.69006\n",
      "[1]\ttrain-logloss:0.68710\teval-logloss:0.68705\n",
      "[2]\ttrain-logloss:0.68417\teval-logloss:0.68409\n",
      "[3]\ttrain-logloss:0.68128\teval-logloss:0.68119\n",
      "[4]\ttrain-logloss:0.67844\teval-logloss:0.67836\n",
      "[5]\ttrain-logloss:0.67565\teval-logloss:0.67558\n",
      "[6]\ttrain-logloss:0.67292\teval-logloss:0.67285\n",
      "[7]\ttrain-logloss:0.67025\teval-logloss:0.67018\n",
      "[8]\ttrain-logloss:0.66765\teval-logloss:0.66753\n",
      "[9]\ttrain-logloss:0.66507\teval-logloss:0.66496\n",
      "[10]\ttrain-logloss:0.66254\teval-logloss:0.66243\n",
      "[11]\ttrain-logloss:0.66005\teval-logloss:0.65996\n",
      "[12]\ttrain-logloss:0.65763\teval-logloss:0.65751\n",
      "[13]\ttrain-logloss:0.65523\teval-logloss:0.65512\n",
      "[14]\ttrain-logloss:0.65290\teval-logloss:0.65276\n",
      "[15]\ttrain-logloss:0.65059\teval-logloss:0.65047\n",
      "[16]\ttrain-logloss:0.64833\teval-logloss:0.64818\n",
      "[17]\ttrain-logloss:0.64611\teval-logloss:0.64597\n",
      "[18]\ttrain-logloss:0.64393\teval-logloss:0.64377\n",
      "[19]\ttrain-logloss:0.64180\teval-logloss:0.64166\n",
      "[20]\ttrain-logloss:0.63969\teval-logloss:0.63952\n",
      "[21]\ttrain-logloss:0.63763\teval-logloss:0.63747\n",
      "[22]\ttrain-logloss:0.63560\teval-logloss:0.63541\n",
      "[23]\ttrain-logloss:0.63360\teval-logloss:0.63340\n",
      "[24]\ttrain-logloss:0.63163\teval-logloss:0.63144\n",
      "[25]\ttrain-logloss:0.62971\teval-logloss:0.62955\n",
      "[26]\ttrain-logloss:0.62782\teval-logloss:0.62762\n",
      "[27]\ttrain-logloss:0.62596\teval-logloss:0.62577\n",
      "[28]\ttrain-logloss:0.62412\teval-logloss:0.62391\n",
      "[29]\ttrain-logloss:0.62232\teval-logloss:0.62208\n",
      "[30]\ttrain-logloss:0.62053\teval-logloss:0.62031\n",
      "[31]\ttrain-logloss:0.61880\teval-logloss:0.61858\n",
      "[32]\ttrain-logloss:0.61707\teval-logloss:0.61685\n",
      "[33]\ttrain-logloss:0.61538\teval-logloss:0.61514\n",
      "[34]\ttrain-logloss:0.61373\teval-logloss:0.61352\n",
      "[35]\ttrain-logloss:0.61210\teval-logloss:0.61185\n",
      "[36]\ttrain-logloss:0.61050\teval-logloss:0.61028\n",
      "[37]\ttrain-logloss:0.60893\teval-logloss:0.60867\n",
      "[38]\ttrain-logloss:0.60736\teval-logloss:0.60713\n",
      "[39]\ttrain-logloss:0.60583\teval-logloss:0.60560\n",
      "[40]\ttrain-logloss:0.60433\teval-logloss:0.60407\n",
      "[41]\ttrain-logloss:0.60286\teval-logloss:0.60262\n",
      "[42]\ttrain-logloss:0.60141\teval-logloss:0.60113\n",
      "[43]\ttrain-logloss:0.59998\teval-logloss:0.59966\n",
      "[44]\ttrain-logloss:0.59855\teval-logloss:0.59827\n",
      "[45]\ttrain-logloss:0.59717\teval-logloss:0.59691\n",
      "[46]\ttrain-logloss:0.59580\teval-logloss:0.59552\n",
      "[47]\ttrain-logloss:0.59447\teval-logloss:0.59421\n",
      "[48]\ttrain-logloss:0.59314\teval-logloss:0.59287\n",
      "[49]\ttrain-logloss:0.59184\teval-logloss:0.59153\n",
      "[50]\ttrain-logloss:0.59057\teval-logloss:0.59024\n",
      "[51]\ttrain-logloss:0.58931\teval-logloss:0.58901\n",
      "[52]\ttrain-logloss:0.58805\teval-logloss:0.58776\n",
      "[53]\ttrain-logloss:0.58683\teval-logloss:0.58653\n",
      "[54]\ttrain-logloss:0.58563\teval-logloss:0.58535\n",
      "[55]\ttrain-logloss:0.58445\teval-logloss:0.58414\n",
      "[56]\ttrain-logloss:0.58326\teval-logloss:0.58297\n",
      "[57]\ttrain-logloss:0.58211\teval-logloss:0.58181\n",
      "[58]\ttrain-logloss:0.58099\teval-logloss:0.58071\n",
      "[59]\ttrain-logloss:0.57988\teval-logloss:0.57960\n",
      "[60]\ttrain-logloss:0.57879\teval-logloss:0.57854\n",
      "[61]\ttrain-logloss:0.57768\teval-logloss:0.57746\n",
      "[62]\ttrain-logloss:0.57662\teval-logloss:0.57637\n",
      "[63]\ttrain-logloss:0.57557\teval-logloss:0.57532\n",
      "[64]\ttrain-logloss:0.57454\teval-logloss:0.57431\n",
      "[65]\ttrain-logloss:0.57353\teval-logloss:0.57329\n",
      "[66]\ttrain-logloss:0.57252\teval-logloss:0.57233\n",
      "[67]\ttrain-logloss:0.57151\teval-logloss:0.57133\n",
      "[68]\ttrain-logloss:0.57053\teval-logloss:0.57042\n",
      "[69]\ttrain-logloss:0.56957\teval-logloss:0.56950\n",
      "[70]\ttrain-logloss:0.56862\teval-logloss:0.56853\n",
      "[71]\ttrain-logloss:0.56769\teval-logloss:0.56761\n",
      "[72]\ttrain-logloss:0.56675\teval-logloss:0.56668\n",
      "[73]\ttrain-logloss:0.56584\teval-logloss:0.56581\n",
      "[74]\ttrain-logloss:0.56494\teval-logloss:0.56496\n",
      "[75]\ttrain-logloss:0.56406\teval-logloss:0.56410\n",
      "[76]\ttrain-logloss:0.56319\teval-logloss:0.56327\n",
      "[77]\ttrain-logloss:0.56234\teval-logloss:0.56242\n",
      "[78]\ttrain-logloss:0.56150\teval-logloss:0.56161\n",
      "[79]\ttrain-logloss:0.56064\teval-logloss:0.56078\n",
      "[80]\ttrain-logloss:0.55981\teval-logloss:0.55999\n",
      "[81]\ttrain-logloss:0.55901\teval-logloss:0.55920\n",
      "[82]\ttrain-logloss:0.55820\teval-logloss:0.55841\n",
      "[83]\ttrain-logloss:0.55743\teval-logloss:0.55766\n",
      "[84]\ttrain-logloss:0.55662\teval-logloss:0.55687\n",
      "[85]\ttrain-logloss:0.55585\teval-logloss:0.55615\n",
      "[86]\ttrain-logloss:0.55510\teval-logloss:0.55542\n",
      "[87]\ttrain-logloss:0.55436\teval-logloss:0.55469\n",
      "[88]\ttrain-logloss:0.55363\teval-logloss:0.55399\n",
      "[89]\ttrain-logloss:0.55291\teval-logloss:0.55325\n",
      "[90]\ttrain-logloss:0.55219\teval-logloss:0.55258\n",
      "[91]\ttrain-logloss:0.55150\teval-logloss:0.55192\n",
      "[92]\ttrain-logloss:0.55078\teval-logloss:0.55121\n",
      "[93]\ttrain-logloss:0.55010\teval-logloss:0.55054\n",
      "[94]\ttrain-logloss:0.54942\teval-logloss:0.54988\n",
      "[95]\ttrain-logloss:0.54876\teval-logloss:0.54923\n",
      "[96]\ttrain-logloss:0.54810\teval-logloss:0.54855\n",
      "[97]\ttrain-logloss:0.54746\teval-logloss:0.54794\n",
      "[98]\ttrain-logloss:0.54682\teval-logloss:0.54731\n",
      "[99]\ttrain-logloss:0.54618\teval-logloss:0.54672\n",
      "[100]\ttrain-logloss:0.54557\teval-logloss:0.54617\n",
      "[101]\ttrain-logloss:0.54493\teval-logloss:0.54554\n",
      "[102]\ttrain-logloss:0.54432\teval-logloss:0.54492\n",
      "[103]\ttrain-logloss:0.54372\teval-logloss:0.54434\n",
      "[104]\ttrain-logloss:0.54314\teval-logloss:0.54377\n",
      "[105]\ttrain-logloss:0.54256\teval-logloss:0.54324\n",
      "[106]\ttrain-logloss:0.54195\teval-logloss:0.54263\n",
      "[107]\ttrain-logloss:0.54139\teval-logloss:0.54210\n",
      "[108]\ttrain-logloss:0.54083\teval-logloss:0.54155\n",
      "[109]\ttrain-logloss:0.54028\teval-logloss:0.54100\n",
      "[110]\ttrain-logloss:0.53974\teval-logloss:0.54052\n",
      "[111]\ttrain-logloss:0.53918\teval-logloss:0.53995\n",
      "[112]\ttrain-logloss:0.53864\teval-logloss:0.53942\n",
      "[113]\ttrain-logloss:0.53813\teval-logloss:0.53892\n",
      "[114]\ttrain-logloss:0.53758\teval-logloss:0.53843\n",
      "[115]\ttrain-logloss:0.53707\teval-logloss:0.53795\n",
      "[116]\ttrain-logloss:0.53656\teval-logloss:0.53744\n",
      "[117]\ttrain-logloss:0.53605\teval-logloss:0.53698\n",
      "[118]\ttrain-logloss:0.53556\teval-logloss:0.53652\n",
      "[119]\ttrain-logloss:0.53507\teval-logloss:0.53604\n",
      "[120]\ttrain-logloss:0.53456\teval-logloss:0.53559\n",
      "[121]\ttrain-logloss:0.53409\teval-logloss:0.53514\n",
      "[122]\ttrain-logloss:0.53363\teval-logloss:0.53471\n",
      "[123]\ttrain-logloss:0.53316\teval-logloss:0.53425\n",
      "[124]\ttrain-logloss:0.53269\teval-logloss:0.53383\n",
      "[125]\ttrain-logloss:0.53225\teval-logloss:0.53340\n",
      "[126]\ttrain-logloss:0.53180\teval-logloss:0.53301\n",
      "[127]\ttrain-logloss:0.53134\teval-logloss:0.53254\n",
      "[128]\ttrain-logloss:0.53090\teval-logloss:0.53211\n",
      "[129]\ttrain-logloss:0.53048\teval-logloss:0.53172\n",
      "[130]\ttrain-logloss:0.53005\teval-logloss:0.53131\n",
      "[131]\ttrain-logloss:0.52961\teval-logloss:0.53093\n",
      "[132]\ttrain-logloss:0.52920\teval-logloss:0.53053\n",
      "[133]\ttrain-logloss:0.52879\teval-logloss:0.53012\n",
      "[134]\ttrain-logloss:0.52837\teval-logloss:0.52975\n",
      "[135]\ttrain-logloss:0.52798\teval-logloss:0.52940\n",
      "[136]\ttrain-logloss:0.52757\teval-logloss:0.52906\n",
      "[137]\ttrain-logloss:0.52718\teval-logloss:0.52868\n",
      "[138]\ttrain-logloss:0.52676\teval-logloss:0.52826\n",
      "[139]\ttrain-logloss:0.52639\teval-logloss:0.52791\n",
      "[140]\ttrain-logloss:0.52598\teval-logloss:0.52749\n",
      "[141]\ttrain-logloss:0.52559\teval-logloss:0.52715\n",
      "[142]\ttrain-logloss:0.52523\teval-logloss:0.52681\n",
      "[143]\ttrain-logloss:0.52487\teval-logloss:0.52648\n",
      "[144]\ttrain-logloss:0.52451\teval-logloss:0.52613\n",
      "[145]\ttrain-logloss:0.52415\teval-logloss:0.52578\n",
      "[146]\ttrain-logloss:0.52379\teval-logloss:0.52547\n",
      "[147]\ttrain-logloss:0.52346\teval-logloss:0.52517\n",
      "[148]\ttrain-logloss:0.52308\teval-logloss:0.52480\n",
      "[149]\ttrain-logloss:0.52271\teval-logloss:0.52444\n",
      "[150]\ttrain-logloss:0.52236\teval-logloss:0.52414\n",
      "[151]\ttrain-logloss:0.52203\teval-logloss:0.52382\n",
      "[152]\ttrain-logloss:0.52171\teval-logloss:0.52350\n",
      "[153]\ttrain-logloss:0.52139\teval-logloss:0.52318\n",
      "[154]\ttrain-logloss:0.52106\teval-logloss:0.52287\n",
      "[155]\ttrain-logloss:0.52074\teval-logloss:0.52256\n",
      "[156]\ttrain-logloss:0.52040\teval-logloss:0.52225\n",
      "[157]\ttrain-logloss:0.52009\teval-logloss:0.52195\n",
      "[158]\ttrain-logloss:0.51976\teval-logloss:0.52167\n",
      "[159]\ttrain-logloss:0.51943\teval-logloss:0.52137\n",
      "[160]\ttrain-logloss:0.51911\teval-logloss:0.52107\n",
      "[161]\ttrain-logloss:0.51880\teval-logloss:0.52081\n",
      "[162]\ttrain-logloss:0.51848\teval-logloss:0.52052\n",
      "[163]\ttrain-logloss:0.51817\teval-logloss:0.52025\n",
      "[164]\ttrain-logloss:0.51788\teval-logloss:0.52001\n",
      "[165]\ttrain-logloss:0.51757\teval-logloss:0.51974\n",
      "[166]\ttrain-logloss:0.51729\teval-logloss:0.51948\n",
      "[167]\ttrain-logloss:0.51700\teval-logloss:0.51918\n",
      "[168]\ttrain-logloss:0.51670\teval-logloss:0.51891\n",
      "[169]\ttrain-logloss:0.51641\teval-logloss:0.51867\n",
      "[170]\ttrain-logloss:0.51612\teval-logloss:0.51841\n",
      "[171]\ttrain-logloss:0.51586\teval-logloss:0.51820\n",
      "[172]\ttrain-logloss:0.51557\teval-logloss:0.51794\n",
      "[173]\ttrain-logloss:0.51528\teval-logloss:0.51770\n",
      "[174]\ttrain-logloss:0.51501\teval-logloss:0.51745\n",
      "[175]\ttrain-logloss:0.51472\teval-logloss:0.51720\n",
      "[176]\ttrain-logloss:0.51445\teval-logloss:0.51695\n",
      "[177]\ttrain-logloss:0.51418\teval-logloss:0.51673\n",
      "[178]\ttrain-logloss:0.51391\teval-logloss:0.51650\n",
      "[179]\ttrain-logloss:0.51364\teval-logloss:0.51626\n",
      "[180]\ttrain-logloss:0.51337\teval-logloss:0.51602\n",
      "[181]\ttrain-logloss:0.51311\teval-logloss:0.51580\n",
      "[182]\ttrain-logloss:0.51285\teval-logloss:0.51557\n",
      "[183]\ttrain-logloss:0.51261\teval-logloss:0.51539\n",
      "[184]\ttrain-logloss:0.51235\teval-logloss:0.51518\n",
      "[185]\ttrain-logloss:0.51210\teval-logloss:0.51496\n",
      "[186]\ttrain-logloss:0.51185\teval-logloss:0.51471\n",
      "[187]\ttrain-logloss:0.51161\teval-logloss:0.51454\n",
      "[188]\ttrain-logloss:0.51136\teval-logloss:0.51434\n",
      "[189]\ttrain-logloss:0.51112\teval-logloss:0.51413\n",
      "[190]\ttrain-logloss:0.51088\teval-logloss:0.51389\n",
      "[191]\ttrain-logloss:0.51064\teval-logloss:0.51369\n",
      "[192]\ttrain-logloss:0.51042\teval-logloss:0.51351\n",
      "[193]\ttrain-logloss:0.51018\teval-logloss:0.51330\n",
      "[194]\ttrain-logloss:0.50994\teval-logloss:0.51311\n",
      "[195]\ttrain-logloss:0.50971\teval-logloss:0.51292\n",
      "[196]\ttrain-logloss:0.50948\teval-logloss:0.51270\n",
      "[197]\ttrain-logloss:0.50925\teval-logloss:0.51252\n",
      "[198]\ttrain-logloss:0.50903\teval-logloss:0.51233\n",
      "[199]\ttrain-logloss:0.50877\teval-logloss:0.51211\n",
      "[200]\ttrain-logloss:0.50855\teval-logloss:0.51189\n",
      "[201]\ttrain-logloss:0.50833\teval-logloss:0.51167\n",
      "[202]\ttrain-logloss:0.50807\teval-logloss:0.51145\n",
      "[203]\ttrain-logloss:0.50784\teval-logloss:0.51127\n",
      "[204]\ttrain-logloss:0.50763\teval-logloss:0.51109\n",
      "[205]\ttrain-logloss:0.50740\teval-logloss:0.51089\n",
      "[206]\ttrain-logloss:0.50719\teval-logloss:0.51072\n",
      "[207]\ttrain-logloss:0.50699\teval-logloss:0.51057\n",
      "[208]\ttrain-logloss:0.50678\teval-logloss:0.51041\n",
      "[209]\ttrain-logloss:0.50657\teval-logloss:0.51023\n",
      "[210]\ttrain-logloss:0.50637\teval-logloss:0.51009\n",
      "[211]\ttrain-logloss:0.50615\teval-logloss:0.50992\n",
      "[212]\ttrain-logloss:0.50597\teval-logloss:0.50977\n",
      "[213]\ttrain-logloss:0.50572\teval-logloss:0.50955\n",
      "[214]\ttrain-logloss:0.50552\teval-logloss:0.50939\n",
      "[215]\ttrain-logloss:0.50533\teval-logloss:0.50924\n",
      "[216]\ttrain-logloss:0.50511\teval-logloss:0.50905\n",
      "[217]\ttrain-logloss:0.50492\teval-logloss:0.50888\n",
      "[218]\ttrain-logloss:0.50472\teval-logloss:0.50869\n",
      "[219]\ttrain-logloss:0.50453\teval-logloss:0.50855\n",
      "[220]\ttrain-logloss:0.50434\teval-logloss:0.50840\n",
      "[221]\ttrain-logloss:0.50411\teval-logloss:0.50819\n",
      "[222]\ttrain-logloss:0.50392\teval-logloss:0.50804\n",
      "[223]\ttrain-logloss:0.50371\teval-logloss:0.50787\n",
      "[224]\ttrain-logloss:0.50354\teval-logloss:0.50774\n",
      "[225]\ttrain-logloss:0.50336\teval-logloss:0.50761\n",
      "[226]\ttrain-logloss:0.50316\teval-logloss:0.50743\n",
      "[227]\ttrain-logloss:0.50299\teval-logloss:0.50730\n",
      "[228]\ttrain-logloss:0.50279\teval-logloss:0.50714\n",
      "[229]\ttrain-logloss:0.50261\teval-logloss:0.50702\n",
      "[230]\ttrain-logloss:0.50242\teval-logloss:0.50682\n",
      "[231]\ttrain-logloss:0.50225\teval-logloss:0.50667\n",
      "[232]\ttrain-logloss:0.50203\teval-logloss:0.50647\n",
      "[233]\ttrain-logloss:0.50186\teval-logloss:0.50635\n",
      "[234]\ttrain-logloss:0.50168\teval-logloss:0.50622\n",
      "[235]\ttrain-logloss:0.50150\teval-logloss:0.50609\n",
      "[236]\ttrain-logloss:0.50135\teval-logloss:0.50597\n",
      "[237]\ttrain-logloss:0.50117\teval-logloss:0.50580\n",
      "[238]\ttrain-logloss:0.50099\teval-logloss:0.50566\n",
      "[239]\ttrain-logloss:0.50080\teval-logloss:0.50552\n",
      "[240]\ttrain-logloss:0.50064\teval-logloss:0.50542\n",
      "[241]\ttrain-logloss:0.50046\teval-logloss:0.50528\n",
      "[242]\ttrain-logloss:0.50029\teval-logloss:0.50513\n",
      "[243]\ttrain-logloss:0.50012\teval-logloss:0.50502\n",
      "[244]\ttrain-logloss:0.49993\teval-logloss:0.50489\n",
      "[245]\ttrain-logloss:0.49978\teval-logloss:0.50474\n",
      "[246]\ttrain-logloss:0.49960\teval-logloss:0.50461\n",
      "[247]\ttrain-logloss:0.49945\teval-logloss:0.50451\n",
      "[248]\ttrain-logloss:0.49928\teval-logloss:0.50439\n",
      "[249]\ttrain-logloss:0.49911\teval-logloss:0.50424\n",
      "[250]\ttrain-logloss:0.49896\teval-logloss:0.50413\n",
      "[251]\ttrain-logloss:0.49879\teval-logloss:0.50401\n",
      "[252]\ttrain-logloss:0.49862\teval-logloss:0.50389\n",
      "[253]\ttrain-logloss:0.49846\teval-logloss:0.50377\n",
      "[254]\ttrain-logloss:0.49832\teval-logloss:0.50365\n",
      "[255]\ttrain-logloss:0.49814\teval-logloss:0.50350\n",
      "[256]\ttrain-logloss:0.49797\teval-logloss:0.50339\n",
      "[257]\ttrain-logloss:0.49781\teval-logloss:0.50325\n",
      "[258]\ttrain-logloss:0.49764\teval-logloss:0.50312\n",
      "[259]\ttrain-logloss:0.49750\teval-logloss:0.50300\n",
      "[260]\ttrain-logloss:0.49733\teval-logloss:0.50290\n",
      "[261]\ttrain-logloss:0.49717\teval-logloss:0.50275\n",
      "[262]\ttrain-logloss:0.49702\teval-logloss:0.50262\n",
      "[263]\ttrain-logloss:0.49688\teval-logloss:0.50249\n",
      "[264]\ttrain-logloss:0.49675\teval-logloss:0.50238\n",
      "[265]\ttrain-logloss:0.49659\teval-logloss:0.50228\n",
      "[266]\ttrain-logloss:0.49646\teval-logloss:0.50218\n",
      "[267]\ttrain-logloss:0.49631\teval-logloss:0.50205\n",
      "[268]\ttrain-logloss:0.49617\teval-logloss:0.50197\n",
      "[269]\ttrain-logloss:0.49600\teval-logloss:0.50182\n",
      "[270]\ttrain-logloss:0.49585\teval-logloss:0.50170\n",
      "[271]\ttrain-logloss:0.49571\teval-logloss:0.50161\n",
      "[272]\ttrain-logloss:0.49552\teval-logloss:0.50143\n",
      "[273]\ttrain-logloss:0.49538\teval-logloss:0.50134\n",
      "[274]\ttrain-logloss:0.49524\teval-logloss:0.50122\n",
      "[275]\ttrain-logloss:0.49510\teval-logloss:0.50113\n",
      "[276]\ttrain-logloss:0.49498\teval-logloss:0.50104\n",
      "[277]\ttrain-logloss:0.49484\teval-logloss:0.50095\n",
      "[278]\ttrain-logloss:0.49467\teval-logloss:0.50078\n",
      "[279]\ttrain-logloss:0.49455\teval-logloss:0.50068\n",
      "[280]\ttrain-logloss:0.49441\teval-logloss:0.50060\n",
      "[281]\ttrain-logloss:0.49428\teval-logloss:0.50052\n",
      "[282]\ttrain-logloss:0.49415\teval-logloss:0.50041\n",
      "[283]\ttrain-logloss:0.49402\teval-logloss:0.50030\n",
      "[284]\ttrain-logloss:0.49389\teval-logloss:0.50022\n",
      "[285]\ttrain-logloss:0.49377\teval-logloss:0.50014\n",
      "[286]\ttrain-logloss:0.49361\teval-logloss:0.50000\n",
      "[287]\ttrain-logloss:0.49345\teval-logloss:0.49985\n",
      "[288]\ttrain-logloss:0.49332\teval-logloss:0.49976\n",
      "[289]\ttrain-logloss:0.49319\teval-logloss:0.49968\n",
      "[290]\ttrain-logloss:0.49306\teval-logloss:0.49958\n",
      "[291]\ttrain-logloss:0.49294\teval-logloss:0.49951\n",
      "[292]\ttrain-logloss:0.49282\teval-logloss:0.49940\n",
      "[293]\ttrain-logloss:0.49270\teval-logloss:0.49932\n",
      "[294]\ttrain-logloss:0.49258\teval-logloss:0.49925\n",
      "[295]\ttrain-logloss:0.49246\teval-logloss:0.49918\n",
      "[296]\ttrain-logloss:0.49235\teval-logloss:0.49909\n",
      "[297]\ttrain-logloss:0.49221\teval-logloss:0.49894\n",
      "[298]\ttrain-logloss:0.49209\teval-logloss:0.49885\n",
      "[299]\ttrain-logloss:0.49197\teval-logloss:0.49877\n",
      "[300]\ttrain-logloss:0.49185\teval-logloss:0.49871\n",
      "[301]\ttrain-logloss:0.49173\teval-logloss:0.49864\n",
      "[302]\ttrain-logloss:0.49162\teval-logloss:0.49855\n",
      "[303]\ttrain-logloss:0.49148\teval-logloss:0.49841\n",
      "[304]\ttrain-logloss:0.49137\teval-logloss:0.49834\n",
      "[305]\ttrain-logloss:0.49127\teval-logloss:0.49828\n",
      "[306]\ttrain-logloss:0.49113\teval-logloss:0.49814\n",
      "[307]\ttrain-logloss:0.49100\teval-logloss:0.49806\n",
      "[308]\ttrain-logloss:0.49089\teval-logloss:0.49799\n",
      "[309]\ttrain-logloss:0.49077\teval-logloss:0.49789\n",
      "[310]\ttrain-logloss:0.49065\teval-logloss:0.49780\n",
      "[311]\ttrain-logloss:0.49055\teval-logloss:0.49773\n",
      "[312]\ttrain-logloss:0.49045\teval-logloss:0.49766\n",
      "[313]\ttrain-logloss:0.49034\teval-logloss:0.49760\n",
      "[314]\ttrain-logloss:0.49021\teval-logloss:0.49751\n",
      "[315]\ttrain-logloss:0.49011\teval-logloss:0.49747\n",
      "[316]\ttrain-logloss:0.49000\teval-logloss:0.49738\n",
      "[317]\ttrain-logloss:0.48990\teval-logloss:0.49729\n",
      "[318]\ttrain-logloss:0.48980\teval-logloss:0.49725\n",
      "[319]\ttrain-logloss:0.48968\teval-logloss:0.49717\n",
      "[320]\ttrain-logloss:0.48959\teval-logloss:0.49711\n",
      "[321]\ttrain-logloss:0.48948\teval-logloss:0.49703\n",
      "[322]\ttrain-logloss:0.48937\teval-logloss:0.49697\n",
      "[323]\ttrain-logloss:0.48925\teval-logloss:0.49690\n",
      "[324]\ttrain-logloss:0.48915\teval-logloss:0.49686\n",
      "[325]\ttrain-logloss:0.48906\teval-logloss:0.49678\n",
      "[326]\ttrain-logloss:0.48895\teval-logloss:0.49671\n",
      "[327]\ttrain-logloss:0.48884\teval-logloss:0.49664\n",
      "[328]\ttrain-logloss:0.48875\teval-logloss:0.49659\n",
      "[329]\ttrain-logloss:0.48865\teval-logloss:0.49650\n",
      "[330]\ttrain-logloss:0.48856\teval-logloss:0.49647\n",
      "[331]\ttrain-logloss:0.48847\teval-logloss:0.49640\n",
      "[332]\ttrain-logloss:0.48838\teval-logloss:0.49637\n",
      "[333]\ttrain-logloss:0.48826\teval-logloss:0.49625\n",
      "[334]\ttrain-logloss:0.48815\teval-logloss:0.49618\n",
      "[335]\ttrain-logloss:0.48805\teval-logloss:0.49610\n",
      "[336]\ttrain-logloss:0.48797\teval-logloss:0.49608\n",
      "[337]\ttrain-logloss:0.48788\teval-logloss:0.49604\n",
      "[338]\ttrain-logloss:0.48778\teval-logloss:0.49598\n",
      "[339]\ttrain-logloss:0.48769\teval-logloss:0.49589\n",
      "[340]\ttrain-logloss:0.48758\teval-logloss:0.49578\n",
      "[341]\ttrain-logloss:0.48747\teval-logloss:0.49571\n",
      "[342]\ttrain-logloss:0.48739\teval-logloss:0.49567\n",
      "[343]\ttrain-logloss:0.48729\teval-logloss:0.49559\n",
      "[344]\ttrain-logloss:0.48722\teval-logloss:0.49558\n",
      "[345]\ttrain-logloss:0.48713\teval-logloss:0.49554\n",
      "[346]\ttrain-logloss:0.48702\teval-logloss:0.49543\n",
      "[347]\ttrain-logloss:0.48694\teval-logloss:0.49540\n",
      "[348]\ttrain-logloss:0.48683\teval-logloss:0.49535\n",
      "[349]\ttrain-logloss:0.48674\teval-logloss:0.49528\n",
      "[350]\ttrain-logloss:0.48666\teval-logloss:0.49522\n",
      "[351]\ttrain-logloss:0.48658\teval-logloss:0.49517\n",
      "[352]\ttrain-logloss:0.48648\teval-logloss:0.49512\n",
      "[353]\ttrain-logloss:0.48638\teval-logloss:0.49507\n",
      "[354]\ttrain-logloss:0.48627\teval-logloss:0.49496\n",
      "[355]\ttrain-logloss:0.48619\teval-logloss:0.49494\n",
      "[356]\ttrain-logloss:0.48610\teval-logloss:0.49487\n",
      "[357]\ttrain-logloss:0.48602\teval-logloss:0.49480\n",
      "[358]\ttrain-logloss:0.48592\teval-logloss:0.49474\n",
      "[359]\ttrain-logloss:0.48585\teval-logloss:0.49471\n",
      "[360]\ttrain-logloss:0.48577\teval-logloss:0.49469\n",
      "[361]\ttrain-logloss:0.48569\teval-logloss:0.49463\n",
      "[362]\ttrain-logloss:0.48557\teval-logloss:0.49455\n",
      "[363]\ttrain-logloss:0.48550\teval-logloss:0.49449\n",
      "[364]\ttrain-logloss:0.48540\teval-logloss:0.49439\n",
      "[365]\ttrain-logloss:0.48532\teval-logloss:0.49435\n",
      "[366]\ttrain-logloss:0.48523\teval-logloss:0.49430\n",
      "[367]\ttrain-logloss:0.48514\teval-logloss:0.49426\n",
      "[368]\ttrain-logloss:0.48504\teval-logloss:0.49421\n",
      "[369]\ttrain-logloss:0.48494\teval-logloss:0.49414\n",
      "[370]\ttrain-logloss:0.48485\teval-logloss:0.49406\n",
      "[371]\ttrain-logloss:0.48479\teval-logloss:0.49405\n",
      "[372]\ttrain-logloss:0.48469\teval-logloss:0.49400\n",
      "[373]\ttrain-logloss:0.48458\teval-logloss:0.49391\n",
      "[374]\ttrain-logloss:0.48448\teval-logloss:0.49381\n",
      "[375]\ttrain-logloss:0.48439\teval-logloss:0.49376\n",
      "[376]\ttrain-logloss:0.48431\teval-logloss:0.49370\n",
      "[377]\ttrain-logloss:0.48421\teval-logloss:0.49363\n",
      "[378]\ttrain-logloss:0.48413\teval-logloss:0.49362\n",
      "[379]\ttrain-logloss:0.48404\teval-logloss:0.49356\n",
      "[380]\ttrain-logloss:0.48395\teval-logloss:0.49350\n",
      "[381]\ttrain-logloss:0.48388\teval-logloss:0.49344\n",
      "[382]\ttrain-logloss:0.48379\teval-logloss:0.49339\n",
      "[383]\ttrain-logloss:0.48372\teval-logloss:0.49338\n",
      "[384]\ttrain-logloss:0.48362\teval-logloss:0.49333\n",
      "[385]\ttrain-logloss:0.48355\teval-logloss:0.49327\n",
      "[386]\ttrain-logloss:0.48347\teval-logloss:0.49322\n",
      "[387]\ttrain-logloss:0.48340\teval-logloss:0.49321\n",
      "[388]\ttrain-logloss:0.48331\teval-logloss:0.49315\n",
      "[389]\ttrain-logloss:0.48324\teval-logloss:0.49310\n",
      "[390]\ttrain-logloss:0.48317\teval-logloss:0.49306\n",
      "[391]\ttrain-logloss:0.48310\teval-logloss:0.49306\n",
      "[392]\ttrain-logloss:0.48303\teval-logloss:0.49304\n",
      "[393]\ttrain-logloss:0.48295\teval-logloss:0.49299\n",
      "[394]\ttrain-logloss:0.48288\teval-logloss:0.49293\n",
      "[395]\ttrain-logloss:0.48280\teval-logloss:0.49288\n",
      "[396]\ttrain-logloss:0.48274\teval-logloss:0.49287\n",
      "[397]\ttrain-logloss:0.48265\teval-logloss:0.49282\n",
      "[398]\ttrain-logloss:0.48257\teval-logloss:0.49277\n",
      "[399]\ttrain-logloss:0.48250\teval-logloss:0.49274\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth' : 3,\n",
    "    'eta' : 0.01,\n",
    "    'booster' : 'gbtree',\n",
    "    'eval_metric' : 'logloss'\n",
    "}\n",
    "num_rounds2 = 400\n",
    "wlist = [(dtrain,'train'),(dval,'eval')]\n",
    "xgb_model2 = xgb.train(params = params, dtrain = dtrain , num_boost_round= num_rounds2, early_stopping_rounds= 100, evals = wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a72cc68-612b-45b9-9ed5-4c33007170e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs2 = xgb_model.predict(dval)\n",
    "preds2 = np.where(pred_probs2 > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47491780-2032-474c-aca0-0efb079e10a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬: \n",
      " [[2945  111]\n",
      " [ 893  551]]\n",
      "\n",
      "정확도:0.7769\n",
      "정밀도:0.8323\n",
      "재현율:0.3816\n",
      "F1:0.5233\n",
      "AUC:0.6726\n"
     ]
    }
   ],
   "source": [
    "def get_clf_eval(y_test, y_pred):\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    F1 = f1_score(y_test, y_pred)\n",
    "    AUC = roc_auc_score(y_test, y_pred)\n",
    "    print('오차행렬: \\n', confusion)\n",
    "    print(f'\\n정확도:{accuracy:.4f}')\n",
    "    print(f'정밀도:{precision:.4f}') \n",
    "    print(f'재현율:{recall:.4f}') \n",
    "    print(f'F1:{F1:.4f}')\n",
    "    print(f'AUC:{AUC:.4f}') \n",
    "    \n",
    "get_clf_eval(y_val, preds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a4ea8c-fbf9-4330-b9bf-2d891375b17b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 훈련 ver3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0666c163-e085-4b3f-84a4-49d803bcfa9d",
   "metadata": {},
   "source": [
    "- train_test_split 의 test_size를 20%\n",
    "- parameter\n",
    "    1. 'max_depth' : 6(default),\n",
    "    2. 'eta' : 0.01,\n",
    "    3. 'booster' :'gbtree',\n",
    "    4.  'eval_metric' : 'logloss'\n",
    "    5.   num_rounds = 400\n",
    "    6.   early_stopping_rounds= 100, \n",
    "    7.   evals = wlist \n",
    "    - max_depth 만 변경\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b40c8e62-9db0-481c-ad21-c21e921550ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 42), (3000, 1))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val , y_train ,y_val = train_test_split(\n",
    "    train_X, train_y, test_size = 0.2 , random_state= 42)\n",
    "\n",
    "# xgb.DMatrix(train_x,train_y)\n",
    "X_train.shape , y_train.shape\n",
    "X_val.shape , y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ae9a224-e439-4b86-92f1-d1576b65f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dval = xgb.DMatrix(X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fce51ca-67b4-400e-abe8-843dc2e077c3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.68920\teval-logloss:0.69034\n",
      "[1]\ttrain-logloss:0.68532\teval-logloss:0.68764\n",
      "[2]\ttrain-logloss:0.68151\teval-logloss:0.68495\n",
      "[3]\ttrain-logloss:0.67780\teval-logloss:0.68236\n",
      "[4]\ttrain-logloss:0.67415\teval-logloss:0.67979\n",
      "[5]\ttrain-logloss:0.67060\teval-logloss:0.67729\n",
      "[6]\ttrain-logloss:0.66710\teval-logloss:0.67486\n",
      "[7]\ttrain-logloss:0.66367\teval-logloss:0.67249\n",
      "[8]\ttrain-logloss:0.66032\teval-logloss:0.67018\n",
      "[9]\ttrain-logloss:0.65700\teval-logloss:0.66794\n",
      "[10]\ttrain-logloss:0.65375\teval-logloss:0.66573\n",
      "[11]\ttrain-logloss:0.65056\teval-logloss:0.66356\n",
      "[12]\ttrain-logloss:0.64744\teval-logloss:0.66142\n",
      "[13]\ttrain-logloss:0.64439\teval-logloss:0.65937\n",
      "[14]\ttrain-logloss:0.64136\teval-logloss:0.65734\n",
      "[15]\ttrain-logloss:0.63841\teval-logloss:0.65535\n",
      "[16]\ttrain-logloss:0.63550\teval-logloss:0.65344\n",
      "[17]\ttrain-logloss:0.63263\teval-logloss:0.65151\n",
      "[18]\ttrain-logloss:0.62984\teval-logloss:0.64963\n",
      "[19]\ttrain-logloss:0.62706\teval-logloss:0.64780\n",
      "[20]\ttrain-logloss:0.62435\teval-logloss:0.64600\n",
      "[21]\ttrain-logloss:0.62170\teval-logloss:0.64422\n",
      "[22]\ttrain-logloss:0.61907\teval-logloss:0.64251\n",
      "[23]\ttrain-logloss:0.61650\teval-logloss:0.64084\n",
      "[24]\ttrain-logloss:0.61396\teval-logloss:0.63923\n",
      "[25]\ttrain-logloss:0.61147\teval-logloss:0.63760\n",
      "[26]\ttrain-logloss:0.60898\teval-logloss:0.63599\n",
      "[27]\ttrain-logloss:0.60654\teval-logloss:0.63446\n",
      "[28]\ttrain-logloss:0.60412\teval-logloss:0.63292\n",
      "[29]\ttrain-logloss:0.60175\teval-logloss:0.63140\n",
      "[30]\ttrain-logloss:0.59941\teval-logloss:0.62992\n",
      "[31]\ttrain-logloss:0.59711\teval-logloss:0.62847\n",
      "[32]\ttrain-logloss:0.59485\teval-logloss:0.62707\n",
      "[33]\ttrain-logloss:0.59262\teval-logloss:0.62575\n",
      "[34]\ttrain-logloss:0.59043\teval-logloss:0.62440\n",
      "[35]\ttrain-logloss:0.58827\teval-logloss:0.62314\n",
      "[36]\ttrain-logloss:0.58614\teval-logloss:0.62190\n",
      "[37]\ttrain-logloss:0.58407\teval-logloss:0.62064\n",
      "[38]\ttrain-logloss:0.58203\teval-logloss:0.61945\n",
      "[39]\ttrain-logloss:0.58001\teval-logloss:0.61825\n",
      "[40]\ttrain-logloss:0.57802\teval-logloss:0.61713\n",
      "[41]\ttrain-logloss:0.57606\teval-logloss:0.61598\n",
      "[42]\ttrain-logloss:0.57413\teval-logloss:0.61491\n",
      "[43]\ttrain-logloss:0.57223\teval-logloss:0.61381\n",
      "[44]\ttrain-logloss:0.57036\teval-logloss:0.61276\n",
      "[45]\ttrain-logloss:0.56852\teval-logloss:0.61171\n",
      "[46]\ttrain-logloss:0.56671\teval-logloss:0.61071\n",
      "[47]\ttrain-logloss:0.56490\teval-logloss:0.60971\n",
      "[48]\ttrain-logloss:0.56316\teval-logloss:0.60875\n",
      "[49]\ttrain-logloss:0.56142\teval-logloss:0.60780\n",
      "[50]\ttrain-logloss:0.55973\teval-logloss:0.60682\n",
      "[51]\ttrain-logloss:0.55797\teval-logloss:0.60581\n",
      "[52]\ttrain-logloss:0.55627\teval-logloss:0.60498\n",
      "[53]\ttrain-logloss:0.55465\teval-logloss:0.60413\n",
      "[54]\ttrain-logloss:0.55296\teval-logloss:0.60317\n",
      "[55]\ttrain-logloss:0.55132\teval-logloss:0.60228\n",
      "[56]\ttrain-logloss:0.54973\teval-logloss:0.60150\n",
      "[57]\ttrain-logloss:0.54818\teval-logloss:0.60073\n",
      "[58]\ttrain-logloss:0.54661\teval-logloss:0.59988\n",
      "[59]\ttrain-logloss:0.54504\teval-logloss:0.59903\n",
      "[60]\ttrain-logloss:0.54353\teval-logloss:0.59819\n",
      "[61]\ttrain-logloss:0.54200\teval-logloss:0.59741\n",
      "[62]\ttrain-logloss:0.54058\teval-logloss:0.59672\n",
      "[63]\ttrain-logloss:0.53910\teval-logloss:0.59592\n",
      "[64]\ttrain-logloss:0.53765\teval-logloss:0.59522\n",
      "[65]\ttrain-logloss:0.53627\teval-logloss:0.59455\n",
      "[66]\ttrain-logloss:0.53486\teval-logloss:0.59382\n",
      "[67]\ttrain-logloss:0.53348\teval-logloss:0.59310\n",
      "[68]\ttrain-logloss:0.53211\teval-logloss:0.59240\n",
      "[69]\ttrain-logloss:0.53077\teval-logloss:0.59179\n",
      "[70]\ttrain-logloss:0.52951\teval-logloss:0.59120\n",
      "[71]\ttrain-logloss:0.52820\teval-logloss:0.59053\n",
      "[72]\ttrain-logloss:0.52691\teval-logloss:0.58989\n",
      "[73]\ttrain-logloss:0.52565\teval-logloss:0.58924\n",
      "[74]\ttrain-logloss:0.52439\teval-logloss:0.58865\n",
      "[75]\ttrain-logloss:0.52316\teval-logloss:0.58809\n",
      "[76]\ttrain-logloss:0.52199\teval-logloss:0.58760\n",
      "[77]\ttrain-logloss:0.52079\teval-logloss:0.58703\n",
      "[78]\ttrain-logloss:0.51963\teval-logloss:0.58653\n",
      "[79]\ttrain-logloss:0.51845\teval-logloss:0.58594\n",
      "[80]\ttrain-logloss:0.51731\teval-logloss:0.58541\n",
      "[81]\ttrain-logloss:0.51617\teval-logloss:0.58487\n",
      "[82]\ttrain-logloss:0.51506\teval-logloss:0.58442\n",
      "[83]\ttrain-logloss:0.51393\teval-logloss:0.58393\n",
      "[84]\ttrain-logloss:0.51290\teval-logloss:0.58350\n",
      "[85]\ttrain-logloss:0.51180\teval-logloss:0.58308\n",
      "[86]\ttrain-logloss:0.51074\teval-logloss:0.58259\n",
      "[87]\ttrain-logloss:0.50974\teval-logloss:0.58217\n",
      "[88]\ttrain-logloss:0.50871\teval-logloss:0.58172\n",
      "[89]\ttrain-logloss:0.50768\teval-logloss:0.58134\n",
      "[90]\ttrain-logloss:0.50666\teval-logloss:0.58097\n",
      "[91]\ttrain-logloss:0.50567\teval-logloss:0.58059\n",
      "[92]\ttrain-logloss:0.50474\teval-logloss:0.58019\n",
      "[93]\ttrain-logloss:0.50377\teval-logloss:0.57979\n",
      "[94]\ttrain-logloss:0.50281\teval-logloss:0.57938\n",
      "[95]\ttrain-logloss:0.50186\teval-logloss:0.57905\n",
      "[96]\ttrain-logloss:0.50092\teval-logloss:0.57867\n",
      "[97]\ttrain-logloss:0.49999\teval-logloss:0.57834\n",
      "[98]\ttrain-logloss:0.49909\teval-logloss:0.57799\n",
      "[99]\ttrain-logloss:0.49819\teval-logloss:0.57766\n",
      "[100]\ttrain-logloss:0.49731\teval-logloss:0.57735\n",
      "[101]\ttrain-logloss:0.49644\teval-logloss:0.57703\n",
      "[102]\ttrain-logloss:0.49553\teval-logloss:0.57664\n",
      "[103]\ttrain-logloss:0.49467\teval-logloss:0.57631\n",
      "[104]\ttrain-logloss:0.49385\teval-logloss:0.57601\n",
      "[105]\ttrain-logloss:0.49297\teval-logloss:0.57564\n",
      "[106]\ttrain-logloss:0.49215\teval-logloss:0.57533\n",
      "[107]\ttrain-logloss:0.49130\teval-logloss:0.57503\n",
      "[108]\ttrain-logloss:0.49049\teval-logloss:0.57477\n",
      "[109]\ttrain-logloss:0.48965\teval-logloss:0.57443\n",
      "[110]\ttrain-logloss:0.48888\teval-logloss:0.57419\n",
      "[111]\ttrain-logloss:0.48813\teval-logloss:0.57393\n",
      "[112]\ttrain-logloss:0.48732\teval-logloss:0.57366\n",
      "[113]\ttrain-logloss:0.48656\teval-logloss:0.57344\n",
      "[114]\ttrain-logloss:0.48578\teval-logloss:0.57313\n",
      "[115]\ttrain-logloss:0.48506\teval-logloss:0.57289\n",
      "[116]\ttrain-logloss:0.48430\teval-logloss:0.57264\n",
      "[117]\ttrain-logloss:0.48358\teval-logloss:0.57241\n",
      "[118]\ttrain-logloss:0.48283\teval-logloss:0.57220\n",
      "[119]\ttrain-logloss:0.48213\teval-logloss:0.57198\n",
      "[120]\ttrain-logloss:0.48140\teval-logloss:0.57172\n",
      "[121]\ttrain-logloss:0.48073\teval-logloss:0.57153\n",
      "[122]\ttrain-logloss:0.48006\teval-logloss:0.57137\n",
      "[123]\ttrain-logloss:0.47937\teval-logloss:0.57122\n",
      "[124]\ttrain-logloss:0.47869\teval-logloss:0.57098\n",
      "[125]\ttrain-logloss:0.47804\teval-logloss:0.57076\n",
      "[126]\ttrain-logloss:0.47736\teval-logloss:0.57052\n",
      "[127]\ttrain-logloss:0.47673\teval-logloss:0.57036\n",
      "[128]\ttrain-logloss:0.47608\teval-logloss:0.57016\n",
      "[129]\ttrain-logloss:0.47540\teval-logloss:0.56998\n",
      "[130]\ttrain-logloss:0.47475\teval-logloss:0.56980\n",
      "[131]\ttrain-logloss:0.47409\teval-logloss:0.56961\n",
      "[132]\ttrain-logloss:0.47353\teval-logloss:0.56946\n",
      "[133]\ttrain-logloss:0.47293\teval-logloss:0.56929\n",
      "[134]\ttrain-logloss:0.47230\teval-logloss:0.56912\n",
      "[135]\ttrain-logloss:0.47167\teval-logloss:0.56896\n",
      "[136]\ttrain-logloss:0.47109\teval-logloss:0.56881\n",
      "[137]\ttrain-logloss:0.47046\teval-logloss:0.56866\n",
      "[138]\ttrain-logloss:0.46990\teval-logloss:0.56854\n",
      "[139]\ttrain-logloss:0.46934\teval-logloss:0.56842\n",
      "[140]\ttrain-logloss:0.46875\teval-logloss:0.56826\n",
      "[141]\ttrain-logloss:0.46818\teval-logloss:0.56813\n",
      "[142]\ttrain-logloss:0.46762\teval-logloss:0.56799\n",
      "[143]\ttrain-logloss:0.46708\teval-logloss:0.56790\n",
      "[144]\ttrain-logloss:0.46651\teval-logloss:0.56778\n",
      "[145]\ttrain-logloss:0.46596\teval-logloss:0.56767\n",
      "[146]\ttrain-logloss:0.46541\teval-logloss:0.56758\n",
      "[147]\ttrain-logloss:0.46490\teval-logloss:0.56751\n",
      "[148]\ttrain-logloss:0.46435\teval-logloss:0.56736\n",
      "[149]\ttrain-logloss:0.46383\teval-logloss:0.56728\n",
      "[150]\ttrain-logloss:0.46328\teval-logloss:0.56713\n",
      "[151]\ttrain-logloss:0.46277\teval-logloss:0.56705\n",
      "[152]\ttrain-logloss:0.46226\teval-logloss:0.56699\n",
      "[153]\ttrain-logloss:0.46172\teval-logloss:0.56685\n",
      "[154]\ttrain-logloss:0.46124\teval-logloss:0.56674\n",
      "[155]\ttrain-logloss:0.46071\teval-logloss:0.56666\n",
      "[156]\ttrain-logloss:0.46022\teval-logloss:0.56656\n",
      "[157]\ttrain-logloss:0.45972\teval-logloss:0.56645\n",
      "[158]\ttrain-logloss:0.45922\teval-logloss:0.56637\n",
      "[159]\ttrain-logloss:0.45875\teval-logloss:0.56631\n",
      "[160]\ttrain-logloss:0.45829\teval-logloss:0.56627\n",
      "[161]\ttrain-logloss:0.45785\teval-logloss:0.56614\n",
      "[162]\ttrain-logloss:0.45736\teval-logloss:0.56605\n",
      "[163]\ttrain-logloss:0.45694\teval-logloss:0.56600\n",
      "[164]\ttrain-logloss:0.45647\teval-logloss:0.56590\n",
      "[165]\ttrain-logloss:0.45599\teval-logloss:0.56580\n",
      "[166]\ttrain-logloss:0.45557\teval-logloss:0.56572\n",
      "[167]\ttrain-logloss:0.45513\teval-logloss:0.56569\n",
      "[168]\ttrain-logloss:0.45468\teval-logloss:0.56564\n",
      "[169]\ttrain-logloss:0.45424\teval-logloss:0.56559\n",
      "[170]\ttrain-logloss:0.45380\teval-logloss:0.56558\n",
      "[171]\ttrain-logloss:0.45337\teval-logloss:0.56551\n",
      "[172]\ttrain-logloss:0.45299\teval-logloss:0.56549\n",
      "[173]\ttrain-logloss:0.45257\teval-logloss:0.56545\n",
      "[174]\ttrain-logloss:0.45217\teval-logloss:0.56541\n",
      "[175]\ttrain-logloss:0.45174\teval-logloss:0.56533\n",
      "[176]\ttrain-logloss:0.45134\teval-logloss:0.56526\n",
      "[177]\ttrain-logloss:0.45091\teval-logloss:0.56524\n",
      "[178]\ttrain-logloss:0.45056\teval-logloss:0.56517\n",
      "[179]\ttrain-logloss:0.45016\teval-logloss:0.56515\n",
      "[180]\ttrain-logloss:0.44975\teval-logloss:0.56505\n",
      "[181]\ttrain-logloss:0.44936\teval-logloss:0.56502\n",
      "[182]\ttrain-logloss:0.44900\teval-logloss:0.56495\n",
      "[183]\ttrain-logloss:0.44863\teval-logloss:0.56492\n",
      "[184]\ttrain-logloss:0.44822\teval-logloss:0.56489\n",
      "[185]\ttrain-logloss:0.44784\teval-logloss:0.56487\n",
      "[186]\ttrain-logloss:0.44748\teval-logloss:0.56483\n",
      "[187]\ttrain-logloss:0.44714\teval-logloss:0.56478\n",
      "[188]\ttrain-logloss:0.44675\teval-logloss:0.56476\n",
      "[189]\ttrain-logloss:0.44640\teval-logloss:0.56474\n",
      "[190]\ttrain-logloss:0.44605\teval-logloss:0.56473\n",
      "[191]\ttrain-logloss:0.44569\teval-logloss:0.56467\n",
      "[192]\ttrain-logloss:0.44534\teval-logloss:0.56462\n",
      "[193]\ttrain-logloss:0.44495\teval-logloss:0.56460\n",
      "[194]\ttrain-logloss:0.44463\teval-logloss:0.56458\n",
      "[195]\ttrain-logloss:0.44431\teval-logloss:0.56453\n",
      "[196]\ttrain-logloss:0.44397\teval-logloss:0.56453\n",
      "[197]\ttrain-logloss:0.44365\teval-logloss:0.56448\n",
      "[198]\ttrain-logloss:0.44333\teval-logloss:0.56444\n",
      "[199]\ttrain-logloss:0.44298\teval-logloss:0.56443\n",
      "[200]\ttrain-logloss:0.44267\teval-logloss:0.56443\n",
      "[201]\ttrain-logloss:0.44237\teval-logloss:0.56443\n",
      "[202]\ttrain-logloss:0.44203\teval-logloss:0.56434\n",
      "[203]\ttrain-logloss:0.44172\teval-logloss:0.56433\n",
      "[204]\ttrain-logloss:0.44141\teval-logloss:0.56434\n",
      "[205]\ttrain-logloss:0.44110\teval-logloss:0.56431\n",
      "[206]\ttrain-logloss:0.44081\teval-logloss:0.56429\n",
      "[207]\ttrain-logloss:0.44048\teval-logloss:0.56424\n",
      "[208]\ttrain-logloss:0.44017\teval-logloss:0.56425\n",
      "[209]\ttrain-logloss:0.43985\teval-logloss:0.56420\n",
      "[210]\ttrain-logloss:0.43951\teval-logloss:0.56421\n",
      "[211]\ttrain-logloss:0.43923\teval-logloss:0.56420\n",
      "[212]\ttrain-logloss:0.43895\teval-logloss:0.56422\n",
      "[213]\ttrain-logloss:0.43869\teval-logloss:0.56420\n",
      "[214]\ttrain-logloss:0.43840\teval-logloss:0.56420\n",
      "[215]\ttrain-logloss:0.43812\teval-logloss:0.56420\n",
      "[216]\ttrain-logloss:0.43783\teval-logloss:0.56418\n",
      "[217]\ttrain-logloss:0.43756\teval-logloss:0.56418\n",
      "[218]\ttrain-logloss:0.43730\teval-logloss:0.56422\n",
      "[219]\ttrain-logloss:0.43703\teval-logloss:0.56420\n",
      "[220]\ttrain-logloss:0.43673\teval-logloss:0.56418\n",
      "[221]\ttrain-logloss:0.43648\teval-logloss:0.56418\n",
      "[222]\ttrain-logloss:0.43621\teval-logloss:0.56421\n",
      "[223]\ttrain-logloss:0.43594\teval-logloss:0.56424\n",
      "[224]\ttrain-logloss:0.43571\teval-logloss:0.56425\n",
      "[225]\ttrain-logloss:0.43547\teval-logloss:0.56424\n",
      "[226]\ttrain-logloss:0.43518\teval-logloss:0.56427\n",
      "[227]\ttrain-logloss:0.43495\teval-logloss:0.56431\n",
      "[228]\ttrain-logloss:0.43468\teval-logloss:0.56432\n",
      "[229]\ttrain-logloss:0.43446\teval-logloss:0.56431\n",
      "[230]\ttrain-logloss:0.43421\teval-logloss:0.56430\n",
      "[231]\ttrain-logloss:0.43391\teval-logloss:0.56428\n",
      "[232]\ttrain-logloss:0.43368\teval-logloss:0.56428\n",
      "[233]\ttrain-logloss:0.43345\teval-logloss:0.56431\n",
      "[234]\ttrain-logloss:0.43320\teval-logloss:0.56435\n",
      "[235]\ttrain-logloss:0.43293\teval-logloss:0.56432\n",
      "[236]\ttrain-logloss:0.43271\teval-logloss:0.56432\n",
      "[237]\ttrain-logloss:0.43245\teval-logloss:0.56433\n",
      "[238]\ttrain-logloss:0.43223\teval-logloss:0.56438\n",
      "[239]\ttrain-logloss:0.43197\teval-logloss:0.56435\n",
      "[240]\ttrain-logloss:0.43171\teval-logloss:0.56434\n",
      "[241]\ttrain-logloss:0.43148\teval-logloss:0.56433\n",
      "[242]\ttrain-logloss:0.43119\teval-logloss:0.56435\n",
      "[243]\ttrain-logloss:0.43098\teval-logloss:0.56432\n",
      "[244]\ttrain-logloss:0.43075\teval-logloss:0.56435\n",
      "[245]\ttrain-logloss:0.43051\teval-logloss:0.56432\n",
      "[246]\ttrain-logloss:0.43024\teval-logloss:0.56433\n",
      "[247]\ttrain-logloss:0.43004\teval-logloss:0.56433\n",
      "[248]\ttrain-logloss:0.42985\teval-logloss:0.56438\n",
      "[249]\ttrain-logloss:0.42961\teval-logloss:0.56442\n",
      "[250]\ttrain-logloss:0.42936\teval-logloss:0.56443\n",
      "[251]\ttrain-logloss:0.42916\teval-logloss:0.56442\n",
      "[252]\ttrain-logloss:0.42887\teval-logloss:0.56443\n",
      "[253]\ttrain-logloss:0.42866\teval-logloss:0.56446\n",
      "[254]\ttrain-logloss:0.42838\teval-logloss:0.56449\n",
      "[255]\ttrain-logloss:0.42817\teval-logloss:0.56453\n",
      "[256]\ttrain-logloss:0.42790\teval-logloss:0.56455\n",
      "[257]\ttrain-logloss:0.42771\teval-logloss:0.56460\n",
      "[258]\ttrain-logloss:0.42744\teval-logloss:0.56464\n",
      "[259]\ttrain-logloss:0.42715\teval-logloss:0.56464\n",
      "[260]\ttrain-logloss:0.42696\teval-logloss:0.56469\n",
      "[261]\ttrain-logloss:0.42673\teval-logloss:0.56469\n",
      "[262]\ttrain-logloss:0.42647\teval-logloss:0.56473\n",
      "[263]\ttrain-logloss:0.42629\teval-logloss:0.56469\n",
      "[264]\ttrain-logloss:0.42604\teval-logloss:0.56471\n",
      "[265]\ttrain-logloss:0.42576\teval-logloss:0.56475\n",
      "[266]\ttrain-logloss:0.42550\teval-logloss:0.56477\n",
      "[267]\ttrain-logloss:0.42520\teval-logloss:0.56479\n",
      "[268]\ttrain-logloss:0.42495\teval-logloss:0.56480\n",
      "[269]\ttrain-logloss:0.42467\teval-logloss:0.56480\n",
      "[270]\ttrain-logloss:0.42440\teval-logloss:0.56483\n",
      "[271]\ttrain-logloss:0.42411\teval-logloss:0.56484\n",
      "[272]\ttrain-logloss:0.42387\teval-logloss:0.56486\n",
      "[273]\ttrain-logloss:0.42369\teval-logloss:0.56489\n",
      "[274]\ttrain-logloss:0.42343\teval-logloss:0.56491\n",
      "[275]\ttrain-logloss:0.42314\teval-logloss:0.56493\n",
      "[276]\ttrain-logloss:0.42291\teval-logloss:0.56493\n",
      "[277]\ttrain-logloss:0.42271\teval-logloss:0.56490\n",
      "[278]\ttrain-logloss:0.42246\teval-logloss:0.56493\n",
      "[279]\ttrain-logloss:0.42219\teval-logloss:0.56492\n",
      "[280]\ttrain-logloss:0.42195\teval-logloss:0.56494\n",
      "[281]\ttrain-logloss:0.42172\teval-logloss:0.56495\n",
      "[282]\ttrain-logloss:0.42145\teval-logloss:0.56498\n",
      "[283]\ttrain-logloss:0.42123\teval-logloss:0.56498\n",
      "[284]\ttrain-logloss:0.42101\teval-logloss:0.56500\n",
      "[285]\ttrain-logloss:0.42077\teval-logloss:0.56502\n",
      "[286]\ttrain-logloss:0.42055\teval-logloss:0.56499\n",
      "[287]\ttrain-logloss:0.42033\teval-logloss:0.56499\n",
      "[288]\ttrain-logloss:0.42012\teval-logloss:0.56497\n",
      "[289]\ttrain-logloss:0.41986\teval-logloss:0.56496\n",
      "[290]\ttrain-logloss:0.41965\teval-logloss:0.56498\n",
      "[291]\ttrain-logloss:0.41939\teval-logloss:0.56496\n",
      "[292]\ttrain-logloss:0.41913\teval-logloss:0.56497\n",
      "[293]\ttrain-logloss:0.41895\teval-logloss:0.56497\n",
      "[294]\ttrain-logloss:0.41876\teval-logloss:0.56498\n",
      "[295]\ttrain-logloss:0.41852\teval-logloss:0.56498\n",
      "[296]\ttrain-logloss:0.41833\teval-logloss:0.56501\n",
      "[297]\ttrain-logloss:0.41810\teval-logloss:0.56502\n",
      "[298]\ttrain-logloss:0.41785\teval-logloss:0.56508\n",
      "[299]\ttrain-logloss:0.41766\teval-logloss:0.56511\n",
      "[300]\ttrain-logloss:0.41748\teval-logloss:0.56512\n",
      "[301]\ttrain-logloss:0.41725\teval-logloss:0.56513\n",
      "[302]\ttrain-logloss:0.41701\teval-logloss:0.56519\n",
      "[303]\ttrain-logloss:0.41684\teval-logloss:0.56523\n",
      "[304]\ttrain-logloss:0.41662\teval-logloss:0.56520\n",
      "[305]\ttrain-logloss:0.41641\teval-logloss:0.56520\n",
      "[306]\ttrain-logloss:0.41617\teval-logloss:0.56525\n",
      "[307]\ttrain-logloss:0.41598\teval-logloss:0.56524\n",
      "[308]\ttrain-logloss:0.41578\teval-logloss:0.56527\n",
      "[309]\ttrain-logloss:0.41556\teval-logloss:0.56527\n",
      "[310]\ttrain-logloss:0.41533\teval-logloss:0.56534\n",
      "[311]\ttrain-logloss:0.41512\teval-logloss:0.56537\n",
      "[312]\ttrain-logloss:0.41490\teval-logloss:0.56542\n",
      "[313]\ttrain-logloss:0.41473\teval-logloss:0.56543\n",
      "[314]\ttrain-logloss:0.41451\teval-logloss:0.56549\n",
      "[315]\ttrain-logloss:0.41431\teval-logloss:0.56549\n",
      "[316]\ttrain-logloss:0.41407\teval-logloss:0.56546\n",
      "[317]\ttrain-logloss:0.41389\teval-logloss:0.56547\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'eta': 0.01,\n",
    "    'booster' : 'gbtree',\n",
    "    'eval_metric' : 'logloss',\n",
    "}\n",
    "num_rounds = 400\n",
    "wlist = [(dtrain,'train'),(dval,'eval')]\n",
    "xgb_model = xgb.train(params = params , dtrain = dtrain, num_boost_round= num_rounds ,evals= wlist,early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4768ea64-6862-4e68-b815-e8dade13fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = xgb_model.predict(dval)\n",
    "preds = np.where(pred_probs > 0.5 , 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7422670-8329-446e-8e6d-c5ac7b294139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬:\n",
      " [[1555   78]\n",
      " [ 790  577]]\n",
      "\n",
      "정확도: 0.7107\n",
      "정밀도: 0.8809\n",
      "재현율: 0.4221\n",
      "F1: 0.5707\n",
      "AUC: 0.6872\n"
     ]
    }
   ],
   "source": [
    "def get_clf_eval(y_test, y_pred):\n",
    "    confusion= confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    F1 = f1_score(y_test,y_pred)\n",
    "    AUC = roc_auc_score(y_test,y_pred)\n",
    "    print('오차행렬:\\n' , confusion)\n",
    "    print(f'\\n정확도: {accuracy:.4f}')\n",
    "    print(f'정밀도: {precision:.4f}')\n",
    "    print(f'재현율: {recall:.4f}')\n",
    "    print(f'F1: {F1:.4f}')\n",
    "    print(f'AUC: {AUC:.4f}')\n",
    "\n",
    "get_clf_eval(y_val, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628ffd70-2c17-4a4c-8cca-557d84fb75b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 훈련 ver 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de652f0-81ea-4213-9a24-7c1753629480",
   "metadata": {},
   "source": [
    "- train_test_split 의 test_size를 20%\n",
    "- parameter\n",
    "    1. 'max_depth' : 3,\n",
    "    2. 'eta' : 0.01,\n",
    "    3. 'booster' :'gbtree',\n",
    "    4.  'eval_metric' : 'err'\n",
    "    5.   num_rounds = 400\n",
    "    6.   early_stopping_rounds= 100, \n",
    "    7.   evals = wlist \n",
    "    - eval_metric 만 변경\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72f8b9a1-da01-4463-bfcb-81b7efa47021",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.22125\teval-error:0.31733\n",
      "[1]\ttrain-error:0.22108\teval-error:0.31967\n",
      "[2]\ttrain-error:0.22058\teval-error:0.31867\n",
      "[3]\ttrain-error:0.22058\teval-error:0.31867\n",
      "[4]\ttrain-error:0.22042\teval-error:0.31900\n",
      "[5]\ttrain-error:0.22042\teval-error:0.31900\n",
      "[6]\ttrain-error:0.22042\teval-error:0.31900\n",
      "[7]\ttrain-error:0.22042\teval-error:0.31900\n",
      "[8]\ttrain-error:0.21917\teval-error:0.31600\n",
      "[9]\ttrain-error:0.21917\teval-error:0.31600\n",
      "[10]\ttrain-error:0.22042\teval-error:0.31900\n",
      "[11]\ttrain-error:0.22042\teval-error:0.31900\n",
      "[12]\ttrain-error:0.22042\teval-error:0.31933\n",
      "[13]\ttrain-error:0.22042\teval-error:0.31933\n",
      "[14]\ttrain-error:0.22042\teval-error:0.32000\n",
      "[15]\ttrain-error:0.22117\teval-error:0.31767\n",
      "[16]\ttrain-error:0.21992\teval-error:0.31467\n",
      "[17]\ttrain-error:0.21992\teval-error:0.31467\n",
      "[18]\ttrain-error:0.22117\teval-error:0.31767\n",
      "[19]\ttrain-error:0.22117\teval-error:0.31767\n",
      "[20]\ttrain-error:0.22117\teval-error:0.31767\n",
      "[21]\ttrain-error:0.22117\teval-error:0.31767\n",
      "[22]\ttrain-error:0.22117\teval-error:0.31767\n",
      "[23]\ttrain-error:0.22117\teval-error:0.31767\n",
      "[24]\ttrain-error:0.22117\teval-error:0.31700\n",
      "[25]\ttrain-error:0.22033\teval-error:0.31533\n",
      "[26]\ttrain-error:0.22042\teval-error:0.31600\n",
      "[27]\ttrain-error:0.22042\teval-error:0.31600\n",
      "[28]\ttrain-error:0.22033\teval-error:0.31533\n",
      "[29]\ttrain-error:0.21992\teval-error:0.31467\n",
      "[30]\ttrain-error:0.22008\teval-error:0.31500\n",
      "[31]\ttrain-error:0.22008\teval-error:0.31500\n",
      "[32]\ttrain-error:0.22033\teval-error:0.31533\n",
      "[33]\ttrain-error:0.21992\teval-error:0.31467\n",
      "[34]\ttrain-error:0.21992\teval-error:0.31500\n",
      "[35]\ttrain-error:0.21992\teval-error:0.31500\n",
      "[36]\ttrain-error:0.21992\teval-error:0.31500\n",
      "[37]\ttrain-error:0.22008\teval-error:0.31500\n",
      "[38]\ttrain-error:0.21992\teval-error:0.31500\n",
      "[39]\ttrain-error:0.21983\teval-error:0.31467\n",
      "[40]\ttrain-error:0.22192\teval-error:0.32067\n",
      "[41]\ttrain-error:0.22208\teval-error:0.32067\n",
      "[42]\ttrain-error:0.22183\teval-error:0.32033\n",
      "[43]\ttrain-error:0.21917\teval-error:0.31767\n",
      "[44]\ttrain-error:0.22075\teval-error:0.32100\n",
      "[45]\ttrain-error:0.21925\teval-error:0.31800\n",
      "[46]\ttrain-error:0.21917\teval-error:0.31767\n",
      "[47]\ttrain-error:0.21900\teval-error:0.31800\n",
      "[48]\ttrain-error:0.22058\teval-error:0.32167\n",
      "[49]\ttrain-error:0.22067\teval-error:0.32067\n",
      "[50]\ttrain-error:0.21892\teval-error:0.31900\n",
      "[51]\ttrain-error:0.22075\teval-error:0.32167\n",
      "[52]\ttrain-error:0.21908\teval-error:0.31867\n",
      "[53]\ttrain-error:0.21917\teval-error:0.32000\n",
      "[54]\ttrain-error:0.22075\teval-error:0.32167\n",
      "[55]\ttrain-error:0.21917\teval-error:0.32000\n",
      "[56]\ttrain-error:0.21925\teval-error:0.31967\n",
      "[57]\ttrain-error:0.21933\teval-error:0.32033\n",
      "[58]\ttrain-error:0.21908\teval-error:0.32000\n",
      "[59]\ttrain-error:0.21908\teval-error:0.32067\n",
      "[60]\ttrain-error:0.21908\teval-error:0.32000\n",
      "[61]\ttrain-error:0.21975\teval-error:0.32167\n",
      "[62]\ttrain-error:0.21975\teval-error:0.32167\n",
      "[63]\ttrain-error:0.21917\teval-error:0.32000\n",
      "[64]\ttrain-error:0.21983\teval-error:0.32133\n",
      "[65]\ttrain-error:0.21975\teval-error:0.32167\n",
      "[66]\ttrain-error:0.21992\teval-error:0.32100\n",
      "[67]\ttrain-error:0.21983\teval-error:0.32067\n",
      "[68]\ttrain-error:0.21958\teval-error:0.32100\n",
      "[69]\ttrain-error:0.21983\teval-error:0.32100\n",
      "[70]\ttrain-error:0.21950\teval-error:0.32167\n",
      "[71]\ttrain-error:0.21983\teval-error:0.32133\n",
      "[72]\ttrain-error:0.21958\teval-error:0.32167\n",
      "[73]\ttrain-error:0.21950\teval-error:0.32167\n",
      "[74]\ttrain-error:0.21925\teval-error:0.32267\n",
      "[75]\ttrain-error:0.21933\teval-error:0.32233\n",
      "[76]\ttrain-error:0.21942\teval-error:0.32233\n",
      "[77]\ttrain-error:0.21967\teval-error:0.32333\n",
      "[78]\ttrain-error:0.21975\teval-error:0.32333\n",
      "[79]\ttrain-error:0.21967\teval-error:0.32333\n",
      "[80]\ttrain-error:0.21950\teval-error:0.32300\n",
      "[81]\ttrain-error:0.21958\teval-error:0.32333\n",
      "[82]\ttrain-error:0.21942\teval-error:0.32267\n",
      "[83]\ttrain-error:0.21942\teval-error:0.32233\n",
      "[84]\ttrain-error:0.21950\teval-error:0.32200\n",
      "[85]\ttrain-error:0.21950\teval-error:0.32200\n",
      "[86]\ttrain-error:0.21958\teval-error:0.32267\n",
      "[87]\ttrain-error:0.21950\teval-error:0.32267\n",
      "[88]\ttrain-error:0.21950\teval-error:0.32267\n",
      "[89]\ttrain-error:0.21908\teval-error:0.32233\n",
      "[90]\ttrain-error:0.21900\teval-error:0.32300\n",
      "[91]\ttrain-error:0.21917\teval-error:0.32300\n",
      "[92]\ttrain-error:0.21908\teval-error:0.32267\n",
      "[93]\ttrain-error:0.21892\teval-error:0.32267\n",
      "[94]\ttrain-error:0.21900\teval-error:0.32300\n",
      "[95]\ttrain-error:0.21917\teval-error:0.32300\n",
      "[96]\ttrain-error:0.21908\teval-error:0.32267\n",
      "[97]\ttrain-error:0.21908\teval-error:0.32333\n",
      "[98]\ttrain-error:0.21917\teval-error:0.32333\n",
      "[99]\ttrain-error:0.21917\teval-error:0.32233\n",
      "[100]\ttrain-error:0.21933\teval-error:0.32233\n",
      "[101]\ttrain-error:0.21925\teval-error:0.32200\n",
      "[102]\ttrain-error:0.21900\teval-error:0.32200\n",
      "[103]\ttrain-error:0.21900\teval-error:0.32200\n",
      "[104]\ttrain-error:0.21908\teval-error:0.32233\n",
      "[105]\ttrain-error:0.21883\teval-error:0.32167\n",
      "[106]\ttrain-error:0.21883\teval-error:0.32233\n",
      "[107]\ttrain-error:0.21875\teval-error:0.32167\n",
      "[108]\ttrain-error:0.21892\teval-error:0.32167\n",
      "[109]\ttrain-error:0.21892\teval-error:0.32167\n",
      "[110]\ttrain-error:0.21908\teval-error:0.32167\n",
      "[111]\ttrain-error:0.21892\teval-error:0.32167\n",
      "[112]\ttrain-error:0.21900\teval-error:0.32167\n",
      "[113]\ttrain-error:0.21908\teval-error:0.32167\n",
      "[114]\ttrain-error:0.21883\teval-error:0.32167\n",
      "[115]\ttrain-error:0.21883\teval-error:0.32167\n",
      "[116]\ttrain-error:0.21867\teval-error:0.32200\n",
      "오차행렬:\n",
      " [[1580   53]\n",
      " [ 913  454]]\n",
      "\n",
      "정확도: 0.6780\n",
      "정밀도: 0.8955\n",
      "재현율: 0.3321\n",
      "F1: 0.4845\n",
      "AUC: 0.6498\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val , y_train ,y_val = train_test_split(\n",
    "    train_X, train_y, test_size = 0.2 , random_state= 42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dval = xgb.DMatrix(X_val,y_val)\n",
    "\n",
    "params = {\n",
    "    'max_depth':3,\n",
    "    'eta': 0.01,\n",
    "    'booster' : 'gbtree',\n",
    "    'eval_metric' : 'error',\n",
    "}\n",
    "num_rounds = 400\n",
    "wlist = [(dtrain,'train'),(dval,'eval')]\n",
    "xgb_model = xgb.train(params = params , dtrain = dtrain, num_boost_round= num_rounds ,evals= wlist,early_stopping_rounds=100)\n",
    "\n",
    "pred_probs = xgb_model.predict(dval)\n",
    "preds = np.where(pred_probs > 0.5 , 1, 0)\n",
    "\n",
    "def get_clf_eval(y_test, y_pred):\n",
    "    confusion= confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    F1 = f1_score(y_test,y_pred)\n",
    "    AUC = roc_auc_score(y_test,y_pred)\n",
    "    print('오차행렬:\\n' , confusion)\n",
    "    print(f'\\n정확도: {accuracy:.4f}')\n",
    "    print(f'정밀도: {precision:.4f}')\n",
    "    print(f'재현율: {recall:.4f}')\n",
    "    print(f'F1: {F1:.4f}')\n",
    "    print(f'AUC: {AUC:.4f}')\n",
    "\n",
    "get_clf_eval(y_val, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceedf2d6-c587-404b-904d-e00ac098deea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 훈련 ver 6\n",
    "\n",
    "- train_test_split 의 test_size를 30%\n",
    "- parameter\n",
    "    1. 'max_depth' : 5,\n",
    "    2. 'eta' : 0.01,\n",
    "    3. 'booster' :'gbtree',\n",
    "    4.  'eval_metric' : 'logloss'\n",
    "    5.   num_rounds = 400\n",
    "    6.   early_stopping_rounds= 100, \n",
    "    7.   evals = wlist \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1d3c43-40d0-461f-a17e-c97b707b9292",
   "metadata": {},
   "source": [
    "분할 기준 \n",
    "\n",
    "한번 분기 마다 변수 영역을 두 개로 구분하는 모델\n",
    "\n",
    "분류나무는 구분 뒤 각 영역의 순도(homogeneity)가 증가 , 불순도(impurity) 혹은 불확실성(uncertainty) 이 최대한 감소하도록 하는 방향으로 학습을 진행한다. 순도가 증가/ 불확실성이 감소하는 두고 정보 이론에서는\n",
    "\n",
    "정보 획득(information gain) 이라고 한다.\n",
    "\n",
    "데이터가 균일한 정도를 나타내는 지표 , 즉 순도를 계산하는 3가지 방식 \n",
    "\n",
    "엔트로피 감소 (= 불확실성 감소=  순도증가 =정보획득)\n",
    "\n",
    "분할 한것이 분할 전보다 낫다는 판단 하에 데이터를 두 개의 부분집합으로 나누게 된다.\n",
    "\n",
    "의사결정나무는 구분 뒤 각 영역의 순도(homogeneity)가 증가/ 불확실성(엔트로피)가 최대한 감소하도록 하는 방향으로 학습을 진행합니다.\n",
    "\n",
    "**순도와 관련해 부연설명을 드리면 A 영역에 속한 모든 레코드가 동일한 범주에 속할 경우(=불확실성 최소=순도 최대) 엔트로피는 0입니다.** \n",
    "\n",
    "**반대로 범주가 둘뿐이고 해당 개체의 수가 동일하게 반반씩 섞여 있을 경우(=불확실성 최대=순도 최소) 엔트로피는 1의 값을 갖습니다. 엔트로피 외에 불순도 지표로 많이 쓰이는 지니계수(Gini Index) 공식은 아래와 같습니다.**\n",
    "\n",
    "**이 예시에서 terminal node는 C,D, E 세 개 인데요, 이를 데이터 공간과 연관지어 생각해보면 전체 데이터 A가 세 개의 부분집합으로 분할된 것 또한 알 수 있습니다.**\n",
    "\n",
    " **D 특성을 갖고 있는 새로운 데이터가 주어졌을 때 의사결정나무는 D 집합을 대표할 수 있는 값(분류=최빈값, 회귀=평균)을 반환하는 방식으로 예측합니다.**\n",
    "\n",
    "분기 지점을 두번째 레코드로 두고 처음 두 개 레코드와 나머지 22개 레코드 간의 엔트로피를 계산한 뒤 정보획득을 알아봅니다. 이렇게 순차적으로 계산한 뒤, 이번엔\n",
    "다른 변수인 소득을 기준으로 정렬하고 다시 같은 작업을 반복합니다. 모든 경우의 수 가운데 정보획득이 가장 큰 변수와 그 지점을\n",
    "택해 첫번째 분기를 하게 됩니다. 이후 또 같은 작업을 반복해 두번째, 세번째… 이렇게 분기를 계속 해 나가는 과정이 바로\n",
    "의사결정나무의 학습입니다.그렇다면 1회 분기를 위해 계산해야 하는 경우의 수는 총 몇 번일까요? 개체가 *𝑛*개, 변수가 *𝑑*개라고 할 때 경우의 수는 *𝑑*(*𝑛*−1) 개가 됩니다. 분기를 하지 않는 경우를 제외하고 모든 개체와 변수를 고려해 보는 것입니다.\n",
    "\n",
    "**의사결정나무는 결정경계(decision boundary)가 데이터 축에 수직이어서 특정 데이터에만 잘 작동할 가능성이 높습니다.**\n",
    "\n",
    "- 보팅과 배깅은 여러 개의 분류기가 투표를 통해 최종 예측 결과를 결정하는 방식인데, 차이점은 보팅은 서로 다른 알고리즘을 가진 분류기를 결합하는 것이고, 배깅은 각각의 분류기가 모두 같은 유형의 알고리즘 기반이지만, 데이터 샘플링을 서로 다르게 가져가면서 학습을 수행해 보팅을 수행한다. 대표적인 배깅은 랜덤 포레스트 알고리즘이다.\n",
    "    부스팅은 여러 개의 분류기가 순차적으로 학습을 수행하되, 예측이 틀린 데이터에 대해 올바르게 예측하도록 가중치를 부여하면서 학습과 예측을 진행하는 것이다.\n",
    "- 보팅 - Hard vs Soft\n",
    "\n",
    "    하드 보팅(Hard Voting)은 다수결 원칙과 유사하다. 즉, 예측한 결괏값들중 다수의 분류기가 결정한 예측값을 최종 보팅 결괏값으로 선정한다.\n",
    "    소프트 보팅(Soft Voting)은 분류기들의 레이블 값 결정 확률을 모두 더해 이를 평균내서 확률이 가장 높은 레이블 값을 최종 보팅 결괏값을 선정한다\n",
    "- XGBoost site : https://injo.tistory.com/44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "748e3598-48ee-4c31-b6db-7d17498d40d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/'\n",
    "train_X = pd.read_csv(PATH+'train_X.csv')\n",
    "train_y = pd.read_csv(PATH+'label.csv')\n",
    "# test_X = pd.read_csv(PATH+'test_X.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ba768b1-dd47-439b-abb6-1e8496213950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬:\n",
      " [[2893  163]\n",
      " [ 802  642]]\n",
      "\n",
      "정확도: 0.7856\n",
      "정밀도: 0.7975\n",
      "재현율: 0.4446\n",
      "F1: 0.5709\n",
      "AUC: 0.6956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmax_depth = 5\\n오차행렬:\\n [[2888  168]\\n [ 797  647]] \\n\\n정확도: 0.7856\\n정밀도: 0.7939\\n재현율: 0.4481\\nF1: 0.5728\\nAUC: 0.6965\\n\\nmax_depth = 4\\n오차행렬:\\n [[2891  165]\\n [ 829  615]]\\n\\n정확도: 0.7791\\n정밀도: 0.7885\\n재현율: 0.4259\\nF1: 0.5531\\nAUC: 0.6860\\n\\nmax_depth= 6\\n\\n오차행렬:\\n [[2874  182]\\n [ 799  645]]\\n\\n정확도: 0.7820\\n정밀도: 0.7799\\n재현율: 0.4467\\nF1: 0.5680\\nAUC: 0.6936\\n\\nmax_depth =5 , early_stopping_rounds=10\\n\\n오차행렬:\\n [[2893  163]\\n [ 802  642]]\\n\\n정확도: 0.7856\\n정밀도: 0.7975\\n재현율: 0.4446\\nF1: 0.5709\\nAUC: 0.6956\\n\\n\\nmax_depth =5 , num_rounds = 500\\n\\n오차행렬:\\n [[2886  170]\\n [ 794  650]]\\n\\n정확도: 0.7858\\n정밀도: 0.7927\\n재현율: 0.4501\\nF1: 0.5742\\nAUC: 0.6973\\n\\nmax_depth =5 , num_rounds = 1000\\n\\n오차행렬:\\n [[2886  170]\\n [ 794  650]]\\n\\n정확도: 0.7858\\n정밀도: 0.7927\\n재현율: 0.4501\\nF1: 0.5742\\nAUC: 0.6973\\n\\nmax_depth =5 , num_rounds = 1000 early_stopping_rounds=10\\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "X_train, X_val , y_train ,y_val = train_test_split(\n",
    "    train_X, train_y, test_size = 0.3 , random_state= 42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dval = xgb.DMatrix(X_val,y_val)\n",
    "\n",
    "params = {\n",
    "    'max_depth':5,\n",
    "    'eta': 0.01,\n",
    "    'booster' : 'gbtree',\n",
    "    'eval_metric' : 'logloss',\n",
    "}\n",
    "num_rounds = 1000\n",
    "wlist = [(dtrain,'train'),(dval,'eval')]\n",
    "xgb_model = xgb.train(params = params , dtrain = dtrain, num_boost_round= num_rounds ,evals= wlist,early_stopping_rounds=10,verbose_eval= 0)\n",
    "\n",
    "pred_probs = xgb_model.predict(dval)\n",
    "preds = np.where(pred_probs > 0.5 , 1, 0)\n",
    "\n",
    "def get_clf_eval(y_test, y_pred):\n",
    "    confusion= confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    F1 = f1_score(y_test,y_pred)\n",
    "    AUC = roc_auc_score(y_test,y_pred)\n",
    "    print('오차행렬:\\n' , confusion)\n",
    "    print(f'\\n정확도: {accuracy:.4f}')\n",
    "    print(f'정밀도: {precision:.4f}')\n",
    "    print(f'재현율: {recall:.4f}')\n",
    "    print(f'F1: {F1:.4f}')\n",
    "    print(f'AUC: {AUC:.4f}')\n",
    "\n",
    "get_clf_eval(y_val, preds)\n",
    "'''\n",
    "max_depth = 5\n",
    "오차행렬:\n",
    " [[2888  168]\n",
    " [ 797  647]] \n",
    "\n",
    "정확도: 0.7856\n",
    "정밀도: 0.7939\n",
    "재현율: 0.4481\n",
    "F1: 0.5728\n",
    "AUC: 0.6965\n",
    "\n",
    "max_depth = 4\n",
    "오차행렬:\n",
    " [[2891  165]\n",
    " [ 829  615]]\n",
    "\n",
    "정확도: 0.7791\n",
    "정밀도: 0.7885\n",
    "재현율: 0.4259\n",
    "F1: 0.5531\n",
    "AUC: 0.6860\n",
    "\n",
    "max_depth= 6\n",
    "\n",
    "오차행렬:\n",
    " [[2874  182]\n",
    " [ 799  645]]\n",
    "\n",
    "정확도: 0.7820\n",
    "정밀도: 0.7799\n",
    "재현율: 0.4467\n",
    "F1: 0.5680\n",
    "AUC: 0.6936\n",
    "\n",
    "max_depth =5 , early_stopping_rounds=10\n",
    "\n",
    "오차행렬:\n",
    " [[2893  163]\n",
    " [ 802  642]]\n",
    "\n",
    "정확도: 0.7856\n",
    "정밀도: 0.7975\n",
    "재현율: 0.4446\n",
    "F1: 0.5709\n",
    "AUC: 0.6956\n",
    "\n",
    "\n",
    "max_depth =5 , num_rounds = 500\n",
    "\n",
    "오차행렬:\n",
    " [[2886  170]\n",
    " [ 794  650]]\n",
    "\n",
    "정확도: 0.7858\n",
    "정밀도: 0.7927\n",
    "재현율: 0.4501\n",
    "F1: 0.5742\n",
    "AUC: 0.6973\n",
    "\n",
    "max_depth =5 , num_rounds = 1000\n",
    "\n",
    "오차행렬:\n",
    " [[2886  170]\n",
    " [ 794  650]]\n",
    "\n",
    "정확도: 0.7858\n",
    "정밀도: 0.7927\n",
    "재현율: 0.4501\n",
    "F1: 0.5742\n",
    "AUC: 0.6973\n",
    "\n",
    "max_depth =5 , num_rounds = 1000 early_stopping_rounds=10\n",
    "\n",
    "오차행렬:\n",
    " [[2893  163]\n",
    " [ 802  642]]\n",
    "\n",
    "정확도: 0.7856\n",
    "정밀도: 0.7975\n",
    "재현율: 0.4446\n",
    "F1: 0.5709\n",
    "AUC: 0.6956\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3e7bf68-93eb-418a-9a63-2805a93b3ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬:\n",
      " [[2902  154]\n",
      " [ 854  590]]\n",
      "\n",
      "정확도: 0.7760\n",
      "정밀도: 0.7930\n",
      "재현율: 0.4086\n",
      "F1: 0.5393\n",
      "AUC: 0.6791\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val , y_train ,y_val = train_test_split(\n",
    "    train_X, train_y, test_size = 0.3 , random_state= 42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dval = xgb.DMatrix(X_val,y_val)\n",
    "\n",
    "params = {\n",
    "    'max_depth':3,\n",
    "    'eta': 0.01,\n",
    "    'booster' : 'gbtree',\n",
    "    'eval_metric' : 'error',\n",
    "}\n",
    "num_rounds = 400\n",
    "wlist = [(dtrain,'train'),(dval,'eval')]\n",
    "xgb_model = xgb.train(params = params , dtrain = dtrain, num_boost_round= num_rounds ,evals= wlist,early_stopping_rounds=100, verbose_eval=0)\n",
    "\n",
    "pred_probs = xgb_model.predict(dval)\n",
    "preds = np.where(pred_probs > 0.5 , 1, 0)\n",
    "\n",
    "def get_clf_eval(y_test, y_pred):\n",
    "    confusion= confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    F1 = f1_score(y_test,y_pred)\n",
    "    AUC = roc_auc_score(y_test,y_pred)\n",
    "    print('오차행렬:\\n' , confusion)\n",
    "    print(f'\\n정확도: {accuracy:.4f}')\n",
    "    print(f'정밀도: {precision:.4f}')\n",
    "    print(f'재현율: {recall:.4f}')\n",
    "    print(f'F1: {F1:.4f}')\n",
    "    print(f'AUC: {AUC:.4f}')\n",
    "\n",
    "get_clf_eval(y_val, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7064767-971d-45f0-b847-3e2e03486b43",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e133293-dfa3-4026-b835-af39860e40af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴드 세트 :  0 시작\n",
      "폴드 세트 :  1 시작\n",
      "폴드 세트 :  2 시작\n",
      "폴드 세트 :  3 시작\n",
      "폴드 세트 :  4 시작\n",
      "폴드 세트 :  0 시작\n",
      "폴드 세트 :  1 시작\n",
      "폴드 세트 :  2 시작\n",
      "폴드 세트 :  3 시작\n",
      "폴드 세트 :  4 시작\n",
      "폴드 세트 :  0 시작\n",
      "폴드 세트 :  1 시작\n",
      "폴드 세트 :  2 시작\n",
      "폴드 세트 :  3 시작\n",
      "폴드 세트 :  4 시작\n",
      "폴드 세트 :  0 시작\n",
      "폴드 세트 :  1 시작\n",
      "폴드 세트 :  2 시작\n",
      "폴드 세트 :  3 시작\n",
      "폴드 세트 :  4 시작\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 4500 and the array at index 3 has size 10500",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m Stack_final_X_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((GBM_train, XGB_train, rf_train,ada_train) , axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# # 개별 모델로부터 나온 y_test 예측값들 옆으로 붙이기\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m Stack_final_X_test \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGBM_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXGB_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mada_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m lr_final\u001b[38;5;241m.\u001b[39mfit(Stack_final_X_train, y_train)\n\u001b[1;32m     70\u001b[0m stack_final \u001b[38;5;241m=\u001b[39m lr_final\u001b[38;5;241m.\u001b[39mpredict(Stack_final_X_test)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 4500 and the array at index 3 has size 10500"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#4개 부터 더 좋다고 하더라\n",
    "\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn.model_selection import KFold , train_test_split\n",
    "PATH = '../data/'\n",
    "train_X = pd.read_csv(PATH+'train_X.csv')\n",
    "train_y = pd.read_csv(PATH+'label.csv')\n",
    "test_X = pd.read_csv(PATH+'test_X.csv')\n",
    "\n",
    "X_train, X_val , y_train ,y_val = train_test_split(\n",
    "    train_X, train_y, test_size = 0.3 , random_state= 42)\n",
    "\n",
    "# X_train.loc[[10000,10001]]\n",
    "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False)\n",
    "    # 빈 배열 생성\n",
    "    train_fold_pred = np.zeros((X_train_n.shape[0],1))\n",
    "    test_pred = np.zeros((X_test_n.shape[0],n_folds))\n",
    "    \n",
    "    for folder_counter,(train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
    "        print('폴드 세트 : ', folder_counter, '시작')\n",
    "        X_tr = X_train_n.iloc[train_index]\n",
    "        y_tr = y_train_n.iloc[train_index]\n",
    "        X_val = X_train_n.iloc[valid_index]\n",
    "        # 폴드 내 모델 학습\n",
    "        # print(train_index, valid_index)\n",
    "        \n",
    "        model.fit(X_tr, y_tr)\n",
    "        train_fold_pred[valid_index,:] = model.predict(X_val).reshape(-1,1)\n",
    "        # y폴드 끝나면_train 예측,  concat해야함\n",
    "        test_pred[:,folder_counter] = model.predict(X_test_n)\n",
    "        # y_test 예측, 폴드 끝나면 평균 낼거임\n",
    "        # print(train_fold_pred[valid_index,:].shape, test_pred[:,folder_counter].shape)\n",
    "        \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)\n",
    "    \n",
    "    return train_fold_pred,test_pred_mean\n",
    "\n",
    "# 객체 생성\n",
    "GBM_clf = GradientBoostingClassifier(n_estimators = 41,learning_rate = 0.1483,\n",
    "                                      subsample=0.95, max_depth=5)\n",
    "    \n",
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_leaf=8,\n",
    "                                min_samples_split=20, random_state=0)\n",
    "\n",
    "XGB_clf = XGBClassifier(n_estimators = 400, learning_rate = 0.01, max_depth = 5, eval_metric = 'logloss')\n",
    "\n",
    "ada_clf = AdaBoostClassifier()\n",
    "\n",
    "lr_final = LogisticRegression()\n",
    "# # 개별 모델로부터 메타 모델에 필요한 데이터 셋 만들기\n",
    "GBM_train, GBM_test = get_stacking_base_datasets(GBM_clf, X_train , y_train, X_val,5)\n",
    "XGB_train, XGB_test = get_stacking_base_datasets(XGB_clf, X_train , y_train, X_val,5) \n",
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train , y_train, X_val,5) \n",
    "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train , y_train, X_val,5) \n",
    "\n",
    "# # 개별 모델로부터 나온 y_train 예측값들 옆으로 붙이기\n",
    "Stack_final_X_train = np.concatenate((GBM_train, XGB_train, rf_train,ada_train) , axis=1)\n",
    "# # 개별 모델로부터 나온 y_test 예측값들 옆으로 붙이기\n",
    "Stack_final_X_test = np.concatenate((GBM_test, XGB_test, rf_test, ada_train), axis =1)\n",
    "\n",
    "lr_final.fit(Stack_final_X_train, y_train)\n",
    "stack_final = lr_final.predict(Stack_final_X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f15bfbb-f84b-4c81-8e74-c1c7d22b0090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = pd.DataFrame([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "# y = pd.DataFrame([1, 2, 3, 4])\n",
    "# kf = KFold(n_splits=2)\n",
    "# kf.get_n_splits(X)\n",
    "\n",
    "# print(kf)\n",
    "# KFold(n_splits=2, random_state=None, shuffle=False)\n",
    "# for train_index, test_index in kf.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "# train_X\n",
    "\n",
    "#(8400,) (2100,) 인덱스 나뉜거\n",
    "\n",
    "# a = np.array([[0],[1],[2]])\n",
    "# a[[0,2],:]\n",
    "\n",
    "# array([[0],\n",
    "#       [2]])\n",
    "\n",
    "# a = np.array([[0],[1],[2]])\n",
    "# a[[0,2],0]\n",
    "\n",
    "# array([0, 2])\n",
    "\n",
    "'''\n",
    "print(train_fold_pred[valid_index,:], test_pred[:,folder_counter])\n",
    "[[1.]\n",
    " [0.]\n",
    " [0.]\n",
    " ...\n",
    " [1.]\n",
    " [0.]\n",
    " [0.]] [0. 0. 1. ... 0. 1. 0.]\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb2e2b-3098-4784-a03d-1f6e777302ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score ,f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, y_pred):\n",
    "    confusion = confusion_matrix(y_test,y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1 = f1_score(y_test, y_pred)\n",
    "    AUC = roc_auc_score(y_test, y_pred)\n",
    "    print('오차행렬:\\n', confusion)\n",
    "    print(f'\\n정확도:: {accuracy:.4f}')\n",
    "    print(f'정밀도: {precision:.4f}')\n",
    "    print(f'재현율: {recall:.4f}')\n",
    "    print(f'F1: {F1:.4f}')\n",
    "    print(f'AUC: {AUC:.4f}')\n",
    "get_clf_eval(y_val, stack_final)\n",
    "'''\n",
    "adaboost 빼고 모델 3개 넣었을때\n",
    "\n",
    "오차행렬:\n",
    " [[2853  203]\n",
    " [ 780  664]]\n",
    "\n",
    "정확도:: 0.7816\n",
    "정밀도: 0.7659\n",
    "재현율: 0.4598\n",
    "F1: 0.5746\n",
    "AUC: 0.6967\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caf63a5-c80a-4c2c-b9c4-ef404727022f",
   "metadata": {},
   "source": [
    "### 교차검증 점수 확인\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8ecaaa-a039-4b9b-a2b6-9d7d80bbf1ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Test & measure performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1dea7474-5cf4-4ad0-a148-7d27bbe724d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict() 수행 결과값을 10개만 표시, 예측 확률 값으로 표시된다\n",
      "[0.353 0.192 0.623 0.42  0.161 0.759 0.553 0.268 0.374 0.129]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs = xgb_model.predict(d_val)\n",
    "# pred_probs = xgb_model.predict(d_test)\n",
    "print('predict() 수행 결과값을 10개만 표시, 예측 확률 값으로 표시된다')\n",
    "print(np.round(pred_probs[:10],3))\n",
    "\n",
    "\n",
    "# 예측 확률이 0.5보다 크면 1 , 그렇지 않으면 0으로 예측값 결정해 리스트 객체인 preds에 저장\n",
    "# 라벨이 1일 확률이네 그러면\n",
    "preds = np.where(pred_probs > 0.5, 1, 0) \n",
    "# len(preds)\n",
    "# y_val = np.array(y_val)\n",
    "# preds.dtype\n",
    "preds\n",
    "# y_val = y_val.reshape(-1).astype('int64')\n",
    "# pd.Series(y_val).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7d8c9087-85de-4e77-934e-5a16001e8fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬:\n",
      " [[1569   64]\n",
      " [ 845  522]]\n",
      "\n",
      "정확도:: 0.6970\n",
      "정밀도: 0.8908\n",
      "재현율: 0.3819\n",
      "F1: 0.5346\n",
      "AUC: 0.6713\n"
     ]
    }
   ],
   "source": [
    "def get_clf_eval(y_test, y_pred):\n",
    "    confusion = confusion_matrix(y_test,y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1 = f1_score(y_test, y_pred)\n",
    "    AUC = roc_auc_score(y_test, y_pred)\n",
    "    print('오차행렬:\\n', confusion)\n",
    "    print(f'\\n정확도:: {accuracy:.4f}')\n",
    "    print(f'정밀도: {precision:.4f}')\n",
    "    print(f'재현율: {recall:.4f}')\n",
    "    print(f'F1: {F1:.4f}')\n",
    "    print(f'AUC: {AUC:.4f}')\n",
    "get_clf_eval(y_val, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfe26ee-c8f1-4a16-9a6f-1e8eff070dab",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Feature importance를 시각화할 때,\n",
    "- 기본 평가 지료로 f1스코어를 기반으로 각 feature의 중요도를 나타냅니다.\n",
    "- 사이킷런 래퍼는 estimator 객체의 featureimportances 속성을 이용해 시각화 코드를 직접 작성해야 합니다.\n",
    "- 반면, 파이썬 래퍼는 plot_importance()를 이용해 바로 피처 중요 코드를 시각화 할 수 있습니다.\n",
    "\n",
    "\n",
    "    - 다만, xgboost 넘파이 기반의 피처 데이터로 학습 시에 피처명을 제대로 알 수 없으므로\n",
    "      피처별로 f자 뒤에 순서를 붙여 X축에 피처들로 나열합니다.(f0는 첫번째 피처, f1는 두번째 피처를 의미)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e1a99-deef-4192-a7f6-08dd070f53e3",
   "metadata": {},
   "source": [
    "# 올릴거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5af98b31-7573-4b40-9e39-349f35e5ecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig , ax = plt.subplots(figsize = (10,10))\n",
    "plot_importance(xgb_model, ax=ax)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ca2e0c-5b78-49aa-9e2c-03744ec72cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c475e7eb-c424-4331-80d0-b8a023f57762",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 제출 파일 만들기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "053ef7b7-a991-48d2-aa05-ce661dce33da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_id_max = 44998\n",
    "test_user_id_min = 30000\n",
    "test_user_number = 14999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d5bbc95-935b-499d-b461-01545c1e6fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 16532648/16532648 [00:15<00:00, 1079829.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14999, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "id_error = test_err[['user_id','errtype']].values\n",
    "test_x = np.zeros((test_user_number,42))\n",
    "for person_idx, err in tqdm(id_error):\n",
    "    # person_idx - test_user_id_min 위치에 person_idx, errtype에 해당하는 error값을 +1\n",
    "    test_x[person_idx - test_user_id_min,err - 1] += 1\n",
    "test_x = test_x.reshape(test_x.shape[0],-1)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7128d42f-9c73-4733-a4fb-489a6e8681b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict(test_x)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b40c03-b58d-4c64-8692-43e6351f6d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c87b82-cc2b-4ede-9b1f-71e897113626",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submssion = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)\n",
    "\n",
    "sample_submssion.to_csv(\"../data/dacon_baseline.csv\", index = False)\n",
    "sample_submssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a3aa7-16be-41eb-83f6-1c6ff6195f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
